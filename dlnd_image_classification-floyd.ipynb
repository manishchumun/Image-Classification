{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 5:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1014, 1: 1014, 2: 952, 3: 1016, 4: 997, 5: 1025, 6: 980, 7: 977, 8: 1003, 9: 1022}\n",
      "First 20 Labels: [1, 8, 5, 1, 5, 7, 4, 3, 8, 2, 7, 2, 0, 1, 5, 9, 6, 2, 0, 8]\n",
      "\n",
      "Example of Image 999:\n",
      "Image - Min Value: 18 Max Value: 224\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 7 Name: horse\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7eff98856860>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 5\n",
    "sample_id = 999\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # since values lie between 0 and 255, we normalise by dividing each value by 255\n",
    "    x = x / 255\n",
    "    \n",
    "    return np.array(x)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "# we can use the LabelBinarizer from preprocessing module in sklearn\n",
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)\n",
    "\n",
    "# we fit outside the function to ensure that the map of encodings is saved\n",
    "lb.fit(np.array([[0,0,0,0,0,0,0,0,0,0]]))\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \n",
    "    \"\"\"\n",
    "    x = lb.transform(x)\n",
    "        \n",
    "    # Change to float32, so it can be multiplied against the features in TensorFlow \n",
    "    x = x.astype(np.float32)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None] + list(image_shape), \"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], \"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, None, \"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    '''\n",
    "    create the weight and bias using conv_ksize, conv_num_outputs and the shape of x_tensor\n",
    "    '''\n",
    "    dimension_x_tensor = x_tensor.get_shape().as_list()\n",
    "    \n",
    "    # (height, width, input_depth, output_depth)\n",
    "    shape = list(conv_ksize + (dimension_x_tensor[-1],) + (conv_num_outputs,))\n",
    "    \n",
    "    # initialise weights using truncated normal distribution\n",
    "    filter_weights = tf.Variable(tf.truncated_normal(shape, mean=0.0, stddev = 0.1))\n",
    "    # set bias to zero\n",
    "    filter_bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    strides =  list((1,) + conv_strides + (1,)) # (batch, height, width, depth)\n",
    "    padding = 'SAME'\n",
    "    \n",
    "    conv = tf.nn.conv2d(x_tensor, filter_weights, strides, padding)\n",
    "    conv = tf.nn.bias_add(conv, filter_bias)\n",
    "    \n",
    "    # Apply non-linear activation\n",
    "    conv = tf.nn.relu(conv)\n",
    "    \n",
    "    # Convolution deep belief networks\n",
    "    # http://www.cs.utoronto.ca/~kriz/conv-cifar10-aug2010.pdf\n",
    "    # conv = tf.nn.relu6(conv)\n",
    "    \n",
    "    \n",
    "    conv = tf.nn.max_pool(conv, ksize=[1] + list(pool_ksize) + [1], strides=[1] + list(pool_strides) + [1], \\\n",
    "                          padding='SAME')\n",
    "    \n",
    "    return conv\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from numpy import prod\n",
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dimension = x_tensor.get_shape().as_list()\n",
    "    return tf.reshape(x_tensor,[-1,prod(dimension[1:])])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dimension = x_tensor.get_shape().as_list()\n",
    "    shape = list((dimension[-1],) + (num_outputs,))\n",
    "    weight = tf.Variable(tf.truncated_normal(shape,mean=0,stddev=0.1))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    connected_layer = tf.add(tf.matmul(x_tensor,weight), bias)\n",
    "    \n",
    "    # Linear activation\n",
    "    return tf.nn.relu(connected_layer)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dimension = x_tensor.get_shape().as_list()\n",
    "    shape = list( (dimension[-1],) + (num_outputs,))\n",
    "    weight = tf.Variable(tf.truncated_normal(shape,mean=0,stddev=0.1))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    output_layer = tf.add(tf.matmul(x_tensor,weight), bias)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv = conv2d_maxpool(x, conv_num_outputs=50, conv_ksize=(4,4), conv_strides=(1,1), \\\n",
    "                          pool_ksize=(4,4), pool_strides=(1,1))\n",
    "    \n",
    "    conv = tf.nn.dropout(conv, keep_prob)\n",
    "    \n",
    "    conv = conv2d_maxpool(x, conv_num_outputs=20, conv_ksize=(4,4), conv_strides=(2,2), \\\n",
    "                           pool_ksize=(4,4), pool_strides=(2,2))\n",
    "    \n",
    "    conv = tf.nn.dropout(conv, keep_prob)\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    conv = flatten(conv)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    conv = fully_conn(conv, 384)\n",
    "    conv = tf.nn.dropout(conv, keep_prob)\n",
    "    \n",
    "    conv = fully_conn(conv, 192)\n",
    "    conv = tf.nn.dropout(conv, keep_prob)\n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    conv = output(conv,10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return conv\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, \\\n",
    "                feed_dict={x:feature_batch, y:label_batch, keep_prob:keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    acc = sess.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.0})\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.2912 Validation Accuracy: 0.170600\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.2791 Validation Accuracy: 0.192600\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.2380 Validation Accuracy: 0.200400\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     2.1114 Validation Accuracy: 0.274800\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.9722 Validation Accuracy: 0.312400\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.8830 Validation Accuracy: 0.349200\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.8416 Validation Accuracy: 0.369000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.7961 Validation Accuracy: 0.384400\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.7490 Validation Accuracy: 0.400000\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.6991 Validation Accuracy: 0.411200\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.6684 Validation Accuracy: 0.418400\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.6276 Validation Accuracy: 0.429600\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.6100 Validation Accuracy: 0.436200\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.5699 Validation Accuracy: 0.443800\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.5483 Validation Accuracy: 0.447600\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.5046 Validation Accuracy: 0.454800\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.4857 Validation Accuracy: 0.460600\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.4691 Validation Accuracy: 0.468000\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.4377 Validation Accuracy: 0.472600\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.4211 Validation Accuracy: 0.475000\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.3930 Validation Accuracy: 0.488200\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.3764 Validation Accuracy: 0.494800\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.3535 Validation Accuracy: 0.495800\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.3154 Validation Accuracy: 0.497400\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.3139 Validation Accuracy: 0.500000\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     1.2896 Validation Accuracy: 0.506400\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     1.2762 Validation Accuracy: 0.505800\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     1.2673 Validation Accuracy: 0.513800\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     1.2581 Validation Accuracy: 0.509600\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     1.2337 Validation Accuracy: 0.513200\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     1.2074 Validation Accuracy: 0.523200\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     1.2036 Validation Accuracy: 0.523200\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     1.1847 Validation Accuracy: 0.529400\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     1.1921 Validation Accuracy: 0.523600\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     1.1710 Validation Accuracy: 0.528200\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     1.1380 Validation Accuracy: 0.537200\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     1.1309 Validation Accuracy: 0.539200\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     1.1290 Validation Accuracy: 0.542400\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     1.1049 Validation Accuracy: 0.544200\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     1.0794 Validation Accuracy: 0.544000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     1.0896 Validation Accuracy: 0.548200\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     1.0597 Validation Accuracy: 0.550400\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     1.0302 Validation Accuracy: 0.558000\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     1.0308 Validation Accuracy: 0.559000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     1.0168 Validation Accuracy: 0.556600\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     1.0065 Validation Accuracy: 0.560000\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     1.0090 Validation Accuracy: 0.553600\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.9945 Validation Accuracy: 0.564000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.9693 Validation Accuracy: 0.561400\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.9639 Validation Accuracy: 0.569800\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     0.9371 Validation Accuracy: 0.569600\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     0.9342 Validation Accuracy: 0.571000\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     0.9233 Validation Accuracy: 0.573400\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     0.9187 Validation Accuracy: 0.572600\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     0.9016 Validation Accuracy: 0.574200\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     0.8879 Validation Accuracy: 0.571200\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     0.8887 Validation Accuracy: 0.582400\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     0.8726 Validation Accuracy: 0.575600\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     0.8527 Validation Accuracy: 0.581000\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     0.8444 Validation Accuracy: 0.579400\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     0.8419 Validation Accuracy: 0.585000\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     0.8468 Validation Accuracy: 0.577200\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     0.8326 Validation Accuracy: 0.583000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     0.8079 Validation Accuracy: 0.587400\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     0.7932 Validation Accuracy: 0.591000\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     0.7738 Validation Accuracy: 0.586000\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     0.7790 Validation Accuracy: 0.584000\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     0.7549 Validation Accuracy: 0.591600\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     0.7704 Validation Accuracy: 0.588600\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     0.7506 Validation Accuracy: 0.590600\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     0.7371 Validation Accuracy: 0.591800\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     0.7226 Validation Accuracy: 0.589000\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     0.7224 Validation Accuracy: 0.587200\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     0.7106 Validation Accuracy: 0.591600\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     0.7052 Validation Accuracy: 0.588600\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     0.6848 Validation Accuracy: 0.592000\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     0.6760 Validation Accuracy: 0.594800\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     0.6580 Validation Accuracy: 0.595600\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     0.6694 Validation Accuracy: 0.597600\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     0.6544 Validation Accuracy: 0.598000\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     0.6510 Validation Accuracy: 0.596400\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     0.6427 Validation Accuracy: 0.599000\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     0.6282 Validation Accuracy: 0.600000\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     0.6234 Validation Accuracy: 0.601400\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     0.6031 Validation Accuracy: 0.604000\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     0.6075 Validation Accuracy: 0.601600\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     0.6000 Validation Accuracy: 0.607800\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     0.5874 Validation Accuracy: 0.611000\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     0.5773 Validation Accuracy: 0.607200\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     0.5695 Validation Accuracy: 0.612000\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     0.5636 Validation Accuracy: 0.609000\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     0.5722 Validation Accuracy: 0.603800\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     0.5482 Validation Accuracy: 0.614000\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     0.5410 Validation Accuracy: 0.605600\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     0.5240 Validation Accuracy: 0.611800\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     0.5359 Validation Accuracy: 0.608000\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     0.5205 Validation Accuracy: 0.612600\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     0.5114 Validation Accuracy: 0.613400\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     0.5006 Validation Accuracy: 0.612200\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     0.4895 Validation Accuracy: 0.613800\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.2973 Validation Accuracy: 0.128800\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     2.2755 Validation Accuracy: 0.211400\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     2.1951 Validation Accuracy: 0.222600\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     1.9975 Validation Accuracy: 0.308200\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     1.9256 Validation Accuracy: 0.356800\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.9174 Validation Accuracy: 0.353200\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     1.7772 Validation Accuracy: 0.363800\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     1.6851 Validation Accuracy: 0.391400\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.6310 Validation Accuracy: 0.407800\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     1.6686 Validation Accuracy: 0.421800\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.6950 Validation Accuracy: 0.433600\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     1.5939 Validation Accuracy: 0.444600\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     1.4592 Validation Accuracy: 0.449400\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.4491 Validation Accuracy: 0.462600\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     1.5057 Validation Accuracy: 0.465800\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.5674 Validation Accuracy: 0.467200\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     1.4457 Validation Accuracy: 0.487000\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     1.3308 Validation Accuracy: 0.481400\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     1.3601 Validation Accuracy: 0.485800\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     1.4065 Validation Accuracy: 0.496400\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.4876 Validation Accuracy: 0.493200\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     1.3835 Validation Accuracy: 0.500600\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     1.2605 Validation Accuracy: 0.500800\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     1.2878 Validation Accuracy: 0.508000\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     1.3417 Validation Accuracy: 0.515400\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.4104 Validation Accuracy: 0.521600\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     1.3197 Validation Accuracy: 0.520600\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     1.2265 Validation Accuracy: 0.515800\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     1.2443 Validation Accuracy: 0.524800\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     1.2854 Validation Accuracy: 0.529800\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.3817 Validation Accuracy: 0.530600\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     1.2564 Validation Accuracy: 0.533200\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     1.1714 Validation Accuracy: 0.536600\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     1.1777 Validation Accuracy: 0.533800\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     1.2477 Validation Accuracy: 0.542600\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.3377 Validation Accuracy: 0.547600\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     1.2291 Validation Accuracy: 0.541800\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     1.1335 Validation Accuracy: 0.549600\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     1.1463 Validation Accuracy: 0.547200\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     1.2194 Validation Accuracy: 0.553600\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.3183 Validation Accuracy: 0.558400\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     1.2078 Validation Accuracy: 0.553600\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     1.1356 Validation Accuracy: 0.545000\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     1.1027 Validation Accuracy: 0.552400\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     1.2001 Validation Accuracy: 0.554000\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.2772 Validation Accuracy: 0.563800\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     1.1771 Validation Accuracy: 0.560000\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     1.1039 Validation Accuracy: 0.550400\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     1.0722 Validation Accuracy: 0.572400\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     1.1664 Validation Accuracy: 0.570800\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.2588 Validation Accuracy: 0.573200\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     1.1410 Validation Accuracy: 0.576000\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     1.0636 Validation Accuracy: 0.569600\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     1.0394 Validation Accuracy: 0.581400\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     1.1242 Validation Accuracy: 0.583000\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.2220 Validation Accuracy: 0.585200\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     1.1247 Validation Accuracy: 0.583000\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     1.0397 Validation Accuracy: 0.582000\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     1.0218 Validation Accuracy: 0.590800\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     1.0804 Validation Accuracy: 0.592600\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.2056 Validation Accuracy: 0.588200\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     1.0896 Validation Accuracy: 0.589000\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     1.0126 Validation Accuracy: 0.591400\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     0.9898 Validation Accuracy: 0.588000\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     1.0783 Validation Accuracy: 0.595200\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.1777 Validation Accuracy: 0.597600\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     1.0591 Validation Accuracy: 0.595000\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     1.0128 Validation Accuracy: 0.590200\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     0.9709 Validation Accuracy: 0.602000\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     1.0322 Validation Accuracy: 0.598200\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.1543 Validation Accuracy: 0.607200\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     1.0407 Validation Accuracy: 0.599400\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     0.9839 Validation Accuracy: 0.597600\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     0.9457 Validation Accuracy: 0.609000\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     1.0193 Validation Accuracy: 0.607400\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.1353 Validation Accuracy: 0.609000\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     1.0254 Validation Accuracy: 0.611200\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     0.9681 Validation Accuracy: 0.610200\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     0.9265 Validation Accuracy: 0.614400\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     0.9923 Validation Accuracy: 0.619000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.1132 Validation Accuracy: 0.615800\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     1.0043 Validation Accuracy: 0.617400\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     0.9480 Validation Accuracy: 0.608800\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     0.9040 Validation Accuracy: 0.625800\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     0.9621 Validation Accuracy: 0.618600\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.0921 Validation Accuracy: 0.623200\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     0.9837 Validation Accuracy: 0.627000\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     0.9078 Validation Accuracy: 0.620800\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     0.8859 Validation Accuracy: 0.622400\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     0.9517 Validation Accuracy: 0.622800\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.0879 Validation Accuracy: 0.619200\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     0.9840 Validation Accuracy: 0.617400\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     0.8876 Validation Accuracy: 0.621000\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     0.8718 Validation Accuracy: 0.624800\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     0.9194 Validation Accuracy: 0.632200\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.0408 Validation Accuracy: 0.632000\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     0.9588 Validation Accuracy: 0.627600\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     0.8825 Validation Accuracy: 0.625600\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     0.8619 Validation Accuracy: 0.635800\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     0.9018 Validation Accuracy: 0.634800\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.0315 Validation Accuracy: 0.633600\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     0.9554 Validation Accuracy: 0.637600\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     0.8621 Validation Accuracy: 0.632800\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     0.8396 Validation Accuracy: 0.638600\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     0.8754 Validation Accuracy: 0.635000\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.0043 Validation Accuracy: 0.639400\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     0.9239 Validation Accuracy: 0.635800\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     0.8614 Validation Accuracy: 0.617000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     0.8366 Validation Accuracy: 0.639200\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     0.8623 Validation Accuracy: 0.636000\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     0.9905 Validation Accuracy: 0.641400\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     0.9078 Validation Accuracy: 0.643200\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     0.8379 Validation Accuracy: 0.633800\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     0.8145 Validation Accuracy: 0.645600\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     0.8479 Validation Accuracy: 0.637400\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     0.9736 Validation Accuracy: 0.649800\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     0.9103 Validation Accuracy: 0.643400\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     0.8140 Validation Accuracy: 0.639800\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     0.7953 Validation Accuracy: 0.648400\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     0.8394 Validation Accuracy: 0.646600\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     0.9477 Validation Accuracy: 0.646200\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     0.9082 Validation Accuracy: 0.635000\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     0.7990 Validation Accuracy: 0.647000\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     0.7831 Validation Accuracy: 0.648200\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     0.8214 Validation Accuracy: 0.647800\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     0.9546 Validation Accuracy: 0.641000\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     0.8633 Validation Accuracy: 0.651200\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     0.7852 Validation Accuracy: 0.649000\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     0.7672 Validation Accuracy: 0.653800\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     0.8076 Validation Accuracy: 0.656800\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.9237 Validation Accuracy: 0.654200\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     0.8475 Validation Accuracy: 0.659000\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     0.7637 Validation Accuracy: 0.655400\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     0.7509 Validation Accuracy: 0.659400\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     0.7909 Validation Accuracy: 0.654800\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.9124 Validation Accuracy: 0.657000\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     0.8331 Validation Accuracy: 0.651600\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     0.7653 Validation Accuracy: 0.654800\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     0.7644 Validation Accuracy: 0.651200\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     0.7634 Validation Accuracy: 0.657800\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.9124 Validation Accuracy: 0.651600\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     0.8463 Validation Accuracy: 0.660400\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     0.7554 Validation Accuracy: 0.656400\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     0.7353 Validation Accuracy: 0.656600\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     0.7772 Validation Accuracy: 0.655000\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.8650 Validation Accuracy: 0.664000\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     0.8133 Validation Accuracy: 0.655800\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     0.7430 Validation Accuracy: 0.662000\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     0.7181 Validation Accuracy: 0.660800\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     0.7575 Validation Accuracy: 0.667200\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     0.8685 Validation Accuracy: 0.658400\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     0.8122 Validation Accuracy: 0.661800\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     0.7403 Validation Accuracy: 0.655200\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     0.7082 Validation Accuracy: 0.662000\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     0.7327 Validation Accuracy: 0.663600\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     0.8452 Validation Accuracy: 0.663200\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     0.8034 Validation Accuracy: 0.666400\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     0.7313 Validation Accuracy: 0.671200\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     0.6851 Validation Accuracy: 0.668400\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     0.7228 Validation Accuracy: 0.668600\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     0.8516 Validation Accuracy: 0.662600\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     0.7840 Validation Accuracy: 0.658600\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     0.7247 Validation Accuracy: 0.658800\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     0.6822 Validation Accuracy: 0.666600\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     0.7108 Validation Accuracy: 0.672600\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     0.8344 Validation Accuracy: 0.658200\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     0.7915 Validation Accuracy: 0.667600\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     0.7073 Validation Accuracy: 0.659600\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     0.6675 Validation Accuracy: 0.669200\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     0.7001 Validation Accuracy: 0.674400\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     0.8005 Validation Accuracy: 0.670800\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     0.7751 Validation Accuracy: 0.671200\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     0.7009 Validation Accuracy: 0.668200\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     0.6575 Validation Accuracy: 0.670400\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     0.6975 Validation Accuracy: 0.668400\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     0.8063 Validation Accuracy: 0.672000\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     0.7526 Validation Accuracy: 0.674200\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     0.6841 Validation Accuracy: 0.668200\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     0.6482 Validation Accuracy: 0.673400\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     0.6800 Validation Accuracy: 0.672000\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     0.7767 Validation Accuracy: 0.673800\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     0.7702 Validation Accuracy: 0.672600\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     0.6803 Validation Accuracy: 0.668200\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     0.6333 Validation Accuracy: 0.678600\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     0.6714 Validation Accuracy: 0.677600\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     0.7729 Validation Accuracy: 0.675000\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     0.7395 Validation Accuracy: 0.670200\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     0.6823 Validation Accuracy: 0.677200\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     0.6338 Validation Accuracy: 0.684800\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     0.6668 Validation Accuracy: 0.684000\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     0.7699 Validation Accuracy: 0.680800\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     0.7397 Validation Accuracy: 0.676800\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     0.6684 Validation Accuracy: 0.675400\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     0.6468 Validation Accuracy: 0.680400\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     0.6385 Validation Accuracy: 0.680600\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     0.7564 Validation Accuracy: 0.682800\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     0.7380 Validation Accuracy: 0.670600\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     0.6653 Validation Accuracy: 0.674600\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     0.6336 Validation Accuracy: 0.684600\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     0.6472 Validation Accuracy: 0.680800\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     0.7446 Validation Accuracy: 0.679800\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     0.7297 Validation Accuracy: 0.674400\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     0.6640 Validation Accuracy: 0.679200\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     0.6079 Validation Accuracy: 0.685000\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     0.6223 Validation Accuracy: 0.690200\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     0.7249 Validation Accuracy: 0.685200\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     0.7221 Validation Accuracy: 0.690000\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     0.6381 Validation Accuracy: 0.689000\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     0.5998 Validation Accuracy: 0.689600\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     0.6191 Validation Accuracy: 0.685400\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     0.7211 Validation Accuracy: 0.682400\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     0.7100 Validation Accuracy: 0.679800\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     0.6348 Validation Accuracy: 0.685200\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     0.5970 Validation Accuracy: 0.684600\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     0.6080 Validation Accuracy: 0.682800\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     0.7005 Validation Accuracy: 0.687600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     0.6961 Validation Accuracy: 0.678000\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     0.6143 Validation Accuracy: 0.685600\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     0.5738 Validation Accuracy: 0.689600\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     0.6059 Validation Accuracy: 0.685200\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     0.6964 Validation Accuracy: 0.690600\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     0.6834 Validation Accuracy: 0.686200\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     0.6120 Validation Accuracy: 0.687800\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     0.5825 Validation Accuracy: 0.685400\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     0.5766 Validation Accuracy: 0.685000\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     0.6965 Validation Accuracy: 0.684600\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     0.6982 Validation Accuracy: 0.681600\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     0.6169 Validation Accuracy: 0.683600\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     0.5639 Validation Accuracy: 0.685400\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     0.5784 Validation Accuracy: 0.684200\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     0.6886 Validation Accuracy: 0.679000\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     0.6819 Validation Accuracy: 0.681400\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     0.5991 Validation Accuracy: 0.686600\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     0.5529 Validation Accuracy: 0.691800\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     0.5854 Validation Accuracy: 0.690800\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.6844 Validation Accuracy: 0.687200\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     0.6806 Validation Accuracy: 0.684600\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     0.5878 Validation Accuracy: 0.689400\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     0.5554 Validation Accuracy: 0.690200\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     0.5654 Validation Accuracy: 0.693200\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.6788 Validation Accuracy: 0.688400\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     0.6617 Validation Accuracy: 0.681400\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     0.6043 Validation Accuracy: 0.682600\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     0.5628 Validation Accuracy: 0.688800\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     0.5685 Validation Accuracy: 0.690800\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.6702 Validation Accuracy: 0.687800\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     0.6590 Validation Accuracy: 0.693400\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     0.5934 Validation Accuracy: 0.680000\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     0.5406 Validation Accuracy: 0.694400\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     0.5545 Validation Accuracy: 0.693000\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     0.6734 Validation Accuracy: 0.689200\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:     0.6424 Validation Accuracy: 0.685400\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:     0.5624 Validation Accuracy: 0.690000\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:     0.5480 Validation Accuracy: 0.689400\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:     0.5409 Validation Accuracy: 0.690800\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     0.6451 Validation Accuracy: 0.688200\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:     0.6380 Validation Accuracy: 0.692000\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:     0.5663 Validation Accuracy: 0.693600\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:     0.5211 Validation Accuracy: 0.697800\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:     0.5357 Validation Accuracy: 0.695800\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     0.6431 Validation Accuracy: 0.699000\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:     0.6400 Validation Accuracy: 0.689800\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:     0.5645 Validation Accuracy: 0.695000\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:     0.5106 Validation Accuracy: 0.694400\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:     0.5325 Validation Accuracy: 0.696000\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     0.6166 Validation Accuracy: 0.696200\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:     0.6237 Validation Accuracy: 0.691600\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:     0.5472 Validation Accuracy: 0.696200\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:     0.5380 Validation Accuracy: 0.689800\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:     0.5309 Validation Accuracy: 0.693800\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     0.6213 Validation Accuracy: 0.690800\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:     0.6201 Validation Accuracy: 0.694400\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:     0.5445 Validation Accuracy: 0.698200\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:     0.5158 Validation Accuracy: 0.693000\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:     0.5187 Validation Accuracy: 0.695000\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     0.5994 Validation Accuracy: 0.694200\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:     0.6042 Validation Accuracy: 0.688400\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:     0.5414 Validation Accuracy: 0.693400\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:     0.5031 Validation Accuracy: 0.693600\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:     0.5167 Validation Accuracy: 0.692600\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     0.6225 Validation Accuracy: 0.693800\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:     0.6019 Validation Accuracy: 0.693000\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:     0.5557 Validation Accuracy: 0.681600\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:     0.5128 Validation Accuracy: 0.696800\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:     0.5053 Validation Accuracy: 0.699800\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     0.6033 Validation Accuracy: 0.692000\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:     0.5926 Validation Accuracy: 0.695800\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:     0.5146 Validation Accuracy: 0.695000\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:     0.4988 Validation Accuracy: 0.699000\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:     0.5057 Validation Accuracy: 0.695200\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     0.5829 Validation Accuracy: 0.700400\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:     0.5933 Validation Accuracy: 0.694800\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:     0.5250 Validation Accuracy: 0.694200\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:     0.4844 Validation Accuracy: 0.695400\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:     0.4954 Validation Accuracy: 0.697400\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     0.5978 Validation Accuracy: 0.694400\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:     0.5945 Validation Accuracy: 0.694200\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:     0.5290 Validation Accuracy: 0.693800\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:     0.4830 Validation Accuracy: 0.697600\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:     0.4887 Validation Accuracy: 0.705000\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     0.5780 Validation Accuracy: 0.702200\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:     0.5789 Validation Accuracy: 0.695000\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:     0.5025 Validation Accuracy: 0.703200\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:     0.4765 Validation Accuracy: 0.704600\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:     0.4774 Validation Accuracy: 0.701800\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     0.5831 Validation Accuracy: 0.701200\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:     0.5864 Validation Accuracy: 0.696400\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:     0.5134 Validation Accuracy: 0.697600\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:     0.4723 Validation Accuracy: 0.706000\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:     0.4842 Validation Accuracy: 0.703400\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     0.5582 Validation Accuracy: 0.704400\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:     0.5650 Validation Accuracy: 0.702600\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:     0.5058 Validation Accuracy: 0.704000\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:     0.4683 Validation Accuracy: 0.704600\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:     0.4839 Validation Accuracy: 0.700400\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     0.5666 Validation Accuracy: 0.697600\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:     0.5721 Validation Accuracy: 0.691400\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:     0.5285 Validation Accuracy: 0.685800\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:     0.4654 Validation Accuracy: 0.708400\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:     0.4785 Validation Accuracy: 0.705000\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     0.5748 Validation Accuracy: 0.706200\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:     0.5488 Validation Accuracy: 0.697600\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:     0.5048 Validation Accuracy: 0.692800\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:     0.4525 Validation Accuracy: 0.697200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, CIFAR-10 Batch 5:  Loss:     0.4657 Validation Accuracy: 0.701400\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     0.5688 Validation Accuracy: 0.704200\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:     0.5547 Validation Accuracy: 0.704200\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:     0.4930 Validation Accuracy: 0.698400\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:     0.4558 Validation Accuracy: 0.703200\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:     0.4623 Validation Accuracy: 0.700400\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     0.5431 Validation Accuracy: 0.704800\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:     0.5501 Validation Accuracy: 0.703400\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:     0.4834 Validation Accuracy: 0.701200\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:     0.4441 Validation Accuracy: 0.709600\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:     0.4598 Validation Accuracy: 0.704400\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     0.5462 Validation Accuracy: 0.706200\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:     0.5244 Validation Accuracy: 0.709000\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:     0.4867 Validation Accuracy: 0.704400\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:     0.4393 Validation Accuracy: 0.704600\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:     0.4459 Validation Accuracy: 0.708200\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     0.5489 Validation Accuracy: 0.706000\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:     0.5218 Validation Accuracy: 0.701400\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:     0.4781 Validation Accuracy: 0.696400\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:     0.4305 Validation Accuracy: 0.709800\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:     0.4391 Validation Accuracy: 0.711400\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     0.5254 Validation Accuracy: 0.710600\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:     0.5263 Validation Accuracy: 0.697400\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:     0.4825 Validation Accuracy: 0.700200\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:     0.4343 Validation Accuracy: 0.712800\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:     0.4253 Validation Accuracy: 0.711000\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     0.5246 Validation Accuracy: 0.711800\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:     0.5095 Validation Accuracy: 0.706400\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:     0.4684 Validation Accuracy: 0.706000\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:     0.4300 Validation Accuracy: 0.709200\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:     0.4453 Validation Accuracy: 0.709000\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     0.5268 Validation Accuracy: 0.703200\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:     0.5208 Validation Accuracy: 0.706400\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:     0.4868 Validation Accuracy: 0.691200\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:     0.4282 Validation Accuracy: 0.708000\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:     0.4304 Validation Accuracy: 0.711600\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     0.5139 Validation Accuracy: 0.710400\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:     0.5116 Validation Accuracy: 0.704600\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:     0.4687 Validation Accuracy: 0.699400\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:     0.4385 Validation Accuracy: 0.706800\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:     0.4266 Validation Accuracy: 0.709800\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     0.5218 Validation Accuracy: 0.709400\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:     0.5100 Validation Accuracy: 0.713200\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:     0.4500 Validation Accuracy: 0.704800\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:     0.4094 Validation Accuracy: 0.712600\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:     0.4315 Validation Accuracy: 0.707400\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     0.5058 Validation Accuracy: 0.709000\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:     0.5058 Validation Accuracy: 0.709400\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:     0.4627 Validation Accuracy: 0.701600\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:     0.4138 Validation Accuracy: 0.714000\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:     0.4281 Validation Accuracy: 0.706200\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     0.4962 Validation Accuracy: 0.709000\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:     0.4939 Validation Accuracy: 0.703400\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:     0.4568 Validation Accuracy: 0.702600\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:     0.4205 Validation Accuracy: 0.711400\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:     0.4184 Validation Accuracy: 0.716000\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     0.4944 Validation Accuracy: 0.708400\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:     0.5007 Validation Accuracy: 0.711400\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:     0.4487 Validation Accuracy: 0.705600\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:     0.4117 Validation Accuracy: 0.714000\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:     0.4074 Validation Accuracy: 0.712200\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     0.4963 Validation Accuracy: 0.706400\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:     0.4865 Validation Accuracy: 0.714200\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:     0.4361 Validation Accuracy: 0.708600\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:     0.4111 Validation Accuracy: 0.704000\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:     0.4285 Validation Accuracy: 0.705000\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     0.5018 Validation Accuracy: 0.705600\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:     0.4868 Validation Accuracy: 0.710400\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:     0.4383 Validation Accuracy: 0.706000\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:     0.3971 Validation Accuracy: 0.715400\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:     0.3970 Validation Accuracy: 0.715200\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     0.4871 Validation Accuracy: 0.708800\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:     0.4877 Validation Accuracy: 0.710200\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:     0.4410 Validation Accuracy: 0.708600\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:     0.3953 Validation Accuracy: 0.711800\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:     0.3942 Validation Accuracy: 0.714400\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     0.4739 Validation Accuracy: 0.712200\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:     0.4665 Validation Accuracy: 0.715400\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:     0.4454 Validation Accuracy: 0.701600\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:     0.3979 Validation Accuracy: 0.711400\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:     0.3941 Validation Accuracy: 0.715800\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     0.4715 Validation Accuracy: 0.715400\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:     0.4688 Validation Accuracy: 0.717800\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:     0.4199 Validation Accuracy: 0.711800\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:     0.3963 Validation Accuracy: 0.710800\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:     0.3984 Validation Accuracy: 0.718600\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     0.4612 Validation Accuracy: 0.717800\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:     0.4609 Validation Accuracy: 0.716800\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:     0.4199 Validation Accuracy: 0.715000\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:     0.3806 Validation Accuracy: 0.721800\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:     0.3874 Validation Accuracy: 0.721200\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     0.4651 Validation Accuracy: 0.718600\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:     0.4541 Validation Accuracy: 0.715000\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:     0.4191 Validation Accuracy: 0.704200\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:     0.3842 Validation Accuracy: 0.714600\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:     0.3948 Validation Accuracy: 0.719200\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     0.4737 Validation Accuracy: 0.709400\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:     0.4492 Validation Accuracy: 0.713600\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:     0.4060 Validation Accuracy: 0.713800\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:     0.3848 Validation Accuracy: 0.715600\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:     0.3920 Validation Accuracy: 0.719400\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     0.4574 Validation Accuracy: 0.715400\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:     0.4508 Validation Accuracy: 0.709000\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:     0.4058 Validation Accuracy: 0.713000\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:     0.3756 Validation Accuracy: 0.718800\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:     0.3851 Validation Accuracy: 0.714400\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     0.4543 Validation Accuracy: 0.719800\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:     0.4392 Validation Accuracy: 0.715400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, CIFAR-10 Batch 3:  Loss:     0.4074 Validation Accuracy: 0.707600\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:     0.3840 Validation Accuracy: 0.714200\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:     0.3766 Validation Accuracy: 0.720000\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     0.4472 Validation Accuracy: 0.712000\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:     0.4306 Validation Accuracy: 0.713800\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:     0.4069 Validation Accuracy: 0.713600\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:     0.3712 Validation Accuracy: 0.712800\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:     0.3785 Validation Accuracy: 0.717600\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     0.4426 Validation Accuracy: 0.712800\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:     0.4477 Validation Accuracy: 0.709400\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:     0.4167 Validation Accuracy: 0.709400\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:     0.3764 Validation Accuracy: 0.706200\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:     0.3856 Validation Accuracy: 0.717400\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     0.4457 Validation Accuracy: 0.717000\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:     0.4326 Validation Accuracy: 0.722000\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:     0.4228 Validation Accuracy: 0.702000\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:     0.3576 Validation Accuracy: 0.717600\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:     0.3784 Validation Accuracy: 0.717000\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     0.4545 Validation Accuracy: 0.713600\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:     0.4253 Validation Accuracy: 0.715200\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:     0.4026 Validation Accuracy: 0.704200\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:     0.3563 Validation Accuracy: 0.712800\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:     0.3681 Validation Accuracy: 0.718600\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     0.4406 Validation Accuracy: 0.715600\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:     0.4268 Validation Accuracy: 0.718200\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:     0.4143 Validation Accuracy: 0.700800\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:     0.3608 Validation Accuracy: 0.715600\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:     0.3647 Validation Accuracy: 0.721200\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     0.4394 Validation Accuracy: 0.717200\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:     0.4079 Validation Accuracy: 0.711600\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:     0.4042 Validation Accuracy: 0.708600\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:     0.3624 Validation Accuracy: 0.719400\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:     0.3645 Validation Accuracy: 0.722000\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     0.4554 Validation Accuracy: 0.722000\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:     0.4113 Validation Accuracy: 0.714600\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:     0.3856 Validation Accuracy: 0.716200\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:     0.3603 Validation Accuracy: 0.714800\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:     0.3704 Validation Accuracy: 0.718800\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     0.4395 Validation Accuracy: 0.717600\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:     0.3981 Validation Accuracy: 0.713600\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:     0.3967 Validation Accuracy: 0.714200\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:     0.3620 Validation Accuracy: 0.711800\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:     0.3469 Validation Accuracy: 0.722400\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     0.4107 Validation Accuracy: 0.719000\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:     0.4132 Validation Accuracy: 0.714000\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:     0.3920 Validation Accuracy: 0.710200\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:     0.3673 Validation Accuracy: 0.713800\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:     0.3664 Validation Accuracy: 0.720000\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     0.4280 Validation Accuracy: 0.711600\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:     0.4056 Validation Accuracy: 0.717800\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:     0.3879 Validation Accuracy: 0.705200\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:     0.3469 Validation Accuracy: 0.713600\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:     0.3528 Validation Accuracy: 0.721000\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     0.4277 Validation Accuracy: 0.717200\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:     0.4061 Validation Accuracy: 0.712200\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:     0.3868 Validation Accuracy: 0.710000\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:     0.3474 Validation Accuracy: 0.715000\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:     0.3506 Validation Accuracy: 0.718800\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     0.4228 Validation Accuracy: 0.714400\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:     0.3889 Validation Accuracy: 0.717000\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:     0.3812 Validation Accuracy: 0.714000\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:     0.3397 Validation Accuracy: 0.712200\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:     0.3658 Validation Accuracy: 0.715400\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     0.4203 Validation Accuracy: 0.719200\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:     0.3972 Validation Accuracy: 0.719400\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:     0.3879 Validation Accuracy: 0.711400\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:     0.3413 Validation Accuracy: 0.715000\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:     0.3576 Validation Accuracy: 0.719600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.7060604333877564\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAIABJREFUeJzs3Xec3FW9//HXZ/umFxISkpDQCR0iQUCaig0VG2BBBX82\nVFQsV2xX7F69V71iu1wvcq2gKHIVEKRKL6EGQmeBFAIJadt3Zz+/P86Z+X73m5nZ2WT7vp95zGMy\n33O+3++ZsjOfOfM555i7IyIiIiIiUDXcDRARERERGSkUHIuIiIiIRAqORUREREQiBcciIiIiIpGC\nYxERERGRSMGxiIiIiEik4FhEREREJFJwLCIiIiISKTgWEREREYkUHIuIiIiIRAqORUREREQiBcci\nIiIiIpGCYxERERGRSMGxiIiIiEik4HiYmdlCM3uLmZ1hZp83s7PN7EwzO8nMXmJmk4a7jaWYWZWZ\nnWhmF5rZ42a22cw8dfnLcLdRZKQxs0WZv5NzBqLuSGVmx2buw2nD3SYRkXJqhrsB45GZzQDOAD4A\nLOyjeo+ZPQTcCFwGXOPu7YPcxD7F+3AxcNxwt0WGnpldALy3j2rdwEZgHXA34TX8e3ffNLitExER\n2XbqOR5iZvZ64CHgG/QdGEN4jvYjBNN/A942eK3rl1/Rj8BYvUfjUg2wA7A38E7gZ8AqMzvHzPTF\nfBTJ/O1eMNztEREZTPqAGkJmdjLwe7b+UrIZeAB4DugApgM7A4uL1B12ZvZS4ITUpqeBrwJ3AVtS\n21uHsl0yKkwEvgIcbWavdfeO4W6QiIhImoLjIWJmuxF6W9PB7nLgi8Dl7t5dZJ9JwDHAScCbgSlD\n0NRKvCVz+0R3v29YWiIjxWcJaTZpNcCOwMuAjxC+8OUdR+hJft+QtE5ERKRCCo6HzjeB+tTtq4E3\nuntbqR3cvZmQZ3yZmZ0JvJ/QuzzclqT+36TAWIB17t5UZPvjwM1mdi7wG8KXvLzTzOxH7n7vUDRw\nNIqPqQ13O7aHu1/PKL8PIjK+jLif7MciM2sE3pja1AW8t1xgnOXuW9z9B+5+9YA3sP9mp/6/etha\nIaOGu7cC7wIeTW024MPD0yIREZHiFBwPjUOAxtTtW9x9NAeV6enluoatFTKqxC+DP8hsfsVwtEVE\nRKQUpVUMjTmZ26uG8uRmNgU4CpgHzCQMmlsL3O7uz2zLIQeweQPCzHYlpHvMB+qAJuA6d3++j/3m\nE3JiFxDu15q438rtaMs8YF9gV2Ba3Pwi8Axw6zifyuyazO3dzKza3XP9OYiZ7QfsA8wlDPJrcvff\nVbBfHXA4sIjwC0gP8Dxw/0CkB5nZHsBSYCegHVgJ3OHuQ/o3X6RdewIHAbMIr8lWwmt9OfCQu/cM\nY/P6ZGYLgJcSctgnE/6eVgM3uvvGAT7XroQOjQVANeG98mZ3f3I7jrkX4fGfQ+hc6AaagWeBx4CH\n3d23s+kiMlDcXZdBvgBvBzx1uWKIzvsS4AqgM3P+9OV+wjRbVuY4x5bZv9Tl+rhv07bum2nDBek6\nqe3HANcRgpzscTqBnwKTihxvH+DyEvv1AH8C5lX4OFfFdvwMeKKP+5YD/gEcV+Gx/zez/3n9eP6/\nndn3r+We536+ti7IHPu0CvdrLPKYzC5SL/26uT61/XRCQJc9xsY+zrsX8DvCF8NSz81K4FNA3TY8\nHkcCt5c4bjdh7MCSWHdRpvycMsetuG6RfacBXyd8KSv3mnwBOB84tI/nuKJLBe8fFb1W4r4nA/eW\nOV9X/Ht6aT+OeX1q/6bU9sMIX96KvSc4cBtweD/OUwt8mpB339fjtpHwnnP8QPx96qKLLtt3GfYG\njIcL8PLMG+EWYNogns+A75Z5ky92uR6YXuJ42Q+3io4X923a1n0zbej1QR23fbzC+3gnqQCZMNtG\nawX7NQELKni837cN99GB/wCq+zj2RODhzH6nVNCmV2Uem5XAzAF8jV2QadNpFe63TcExYTDrH8o8\nlkWDY8LfwtcIQVSlz8vySp731Dm+UOHrsJOQd70os/2cMseuuG5mvzcDG/r5ery3j+e4oksF7x99\nvlYIM/Nc3c9z/xCoquDY16f2aYrbzqR8J0L6OTy5gnPMIix809/H7y8D9Teqiy66bPtFaRVDYxmh\nx7A63p4E/MrM3ulhRoqB9t/A/8ts6yT0fKwm9Ci9hLBAQ94xwD/N7Gh33zAIbRpQcc7o/4w3ndC7\n9AQhGDoI2C1V/SXAucDpZnYccBFJStHD8dJJmFd6/9R+C6lssZNs7n4b8CDhZ+vNhIBwZ+AAQspH\n3qcIQdvZpQ7s7i3xvt4ONMTN55nZXe7+RLF9zGwO8GuS9Jcc8E53X9/H/RgK8zK3HaikXT8kTGmY\n3+cekgB6V2CX7A5mZoSe93dnitoIgUs+7393wmsm/3jtC9xiZoe6e9nZYczsk4SZaNJyhOfrWUIK\nwMGE9I9aQsCZ/dscULFN32fr9KfnCL8UrQMmEFKQ9qf3LDrDzswmAzcQnpO0DcAd8XouIc0i3fZP\nEN7TTu3n+U4FfpTatJzQ29tBeB9ZQvJY1gIXmNk97v5YieMZ8GfC8562ljCf/TrCl6mp8fi7oxRH\nkZFluKPz8XIhrG6X7SVYTVgQYX8G7ufu92bO0UMILKZl6tUQPqQ3Zer/vsgxGwg9WPnLylT92zJl\n+cucuO/8eDubWvKZEvsV9s204YLM/vlesb8BuxWpfzIhCEo/DofHx9yBW4CDiux3LCFYS5/rdX08\n5vkp9r4dz1G0N5jwpeRzQEumXYdV8Lx+ONOmuyjy8z8hUM/2uH15EF7P2efjtAr3+2Bmv8dL1GtK\n1UmnQvwamF+k/qIi287OnOvF+Dg2FKm7C3Bppv6VlE832p+text/l339xufkZEJuc74d6X3OKXOO\nRZXWjfVfTQjO0/vcABxR7L4Qgss3EH7SX5Yp24HkbzJ9vIsp/bdb7Hk4tj+vFeCXmfqbgQ8BtZl6\nUwm/vmR77T/Ux/GvT9VtJnmfuATYvUj9xcB9mXNcVOb4J2TqPkYYeFr0tUT4dehE4ELgjwP9t6qL\nLrr0/zLsDRgvF0IvSHvmTTN9WU/IS/wycDwwcRvOMYmQu5Y+7ll97HMYvYM1p4+8N0rkg/axT78+\nIIvsf0GRx+y3lPkZlbDkdrGA+mqgvsx+r6/0gzDWn1PueEXqH555LZQ9fmq/bFrBfxap88VMnWvK\nPUbb8XrOPh99Pp+EL1krMvsVzaGmeDrOt/vRvn3pnUrxLEUCt8w+Rsi9TZ/zhDL1r8vU/XEFbcoG\nxgMWHBN6g9dm21Tp8w/sWKYsfcwL+vlaqfhvnzBwOF23FTiyj+N/LLNPMyVSxGL964s8Bz+m/Beh\nHemdptJe6hyEsQf5el3ALv14rLb64qaLLroM/UVTuQ0RDwsdvJvwplrMDOB1hPzIq4ANZnajmX0o\nzjZRifcSelPy/u7u2amzsu26HfjXzOZPVHi+4bSa0ENUbpT9/xB6xvPyo/Tf7WWWLXb3vwGPpDYd\nW64h7v5cueMVqX8r8JPUpjeZWSU/bb8fSI+Y/7iZnZi/YWYvIyzjnfcCcGofj9GQMLMGQq/v3pmi\n/6rwEPcCX+rHKf+F5KdqB07y4ouUFLi7E1byS89UUvRvwcz2pffr4lFCmky54z8Y2zVYPkDvOciv\nA86s9Pl397WD0qr++Xjm9lfd/eZyO7j7jwm/IOVNpH+pK8sJnQhe5hxrCUFvXj0hraOY9EqQ97r7\nU5U2xN1LfT6IyBBScDyE3P2PhJ83b6qgei1hirGfA0+a2UdiLls578rc/kqFTfsRIZDKe52Zzahw\n3+FynveRr+3unUD2g/VCd19TwfGvTf1/dszjHUiXpv5fx9b5lVtx983AKYSf8vN+aWY7m9lM4Pck\nee0OvKfC+zoQdjCzRZnL7mZ2hJn9C/AQ8LbMPr9192UVHv+HXuF0b2Y2DXhHatNl7n5bJfvG4OS8\n1KbjzGxCkarZv7XvxtdbX85n8KZy/EDmdtmAb6Qxs4nAm1KbNhBSwiqR/eLUn7zjH7h7JfO1X565\nfWAF+8zqRztEZIRQcDzE3P0edz8KOJrQs1l2Ht5oJqGn8cI4T+tWYs9jelnnJ939jgrb1AX8MX04\nSveKjBRXVVgvO2jtHxXu93jmdr8/5CyYbGY7ZQNHth4sle1RLcrd7yLkLedNJwTFFxDyu/O+5+5/\n72+bt8P3gKcyl8cIX07+ja0HzN3M1sFcOX/tR90jCV8u8y7ux74AN6b+X0NIPco6PPX//NR/fYq9\nuH/ss2I/mdksQtpG3p0++pZ1P5TeA9MuqfQXmXhfH0pt2j8O7KtEpX8nD2dul3pPSP/qtNDMPlrh\n8UVkhNAI2WHi7jcSP4TNbB9Cj/JLCB8QB1H8i8vJhJHOxd5s96P3TAi397NJtxF+Us5bwtY9JSNJ\n9oOqlM2Z248UrdX3fn2mtphZNfBKwqwKhxIC3qJfZoqYXmE93P2HcdaN/JLkR2Sq3EbIPR6J2giz\njPxrhb11AM+4+4v9OMeRmdvr4xeSSlVnbhfb95DU/x/z/i1EcWc/6lYqG8DfWLTWyLYkc3tb3sP2\nif+vIryP9vU4bPbKVyvNLt5T6j3hQuCs1O0fm9mbCAMNr/BRMBuQyHin4HgEcPeHCL0ev4DCz8Jv\nIrzBHpCp/hEz+x93vzuzPduLUXSaoTKyQeNI/zmw0lXmugdov9qitSIzO5yQP7t/uXplVJpXnnc6\nYTqznTPbNwLvcPds+4dDjvB4rye09Ubgd/0MdKF3yk8l5mdu96fXuZheKUYxfzr9fBWdUq+M7K8S\nAyGb9rNiEM4x2IbjPazi1SrdvSuT2Vb0PcHd7zCzn9K7s+GV8dJjZg8Qfjn5JxWs4ikiQ09pFSOQ\nu2909wsIPR9fK1IlO2gFkmWK87I9n33JfkhU3JM5HLZjkNmAD04zs9cQBj9ta2AM/fxbjAHmt4oU\nfbqvgWeD5HR3t8ylxt1nuvue7n6Ku/94GwJjCLMP9MdA58tPytwe6L+1gTAzc3tAl1QeIsPxHjZY\ng1U/Rvj1pjWzvYqQq/wRQg/zGjO7zszeVsGYEhEZIgqORzAPvkJYtCLtlcPRHtlaHLj4G3ovRtBE\nWLb3tYRli6cRpmgqBI4UWbSin+edSZj2L+tUMxvvf9dle/m3wWgMWkbNQLyxKL53f4uwQM3ngFvZ\n+tcoCJ/BxxLy0G8ws7lD1kgRKUlpFaPDuYRZCvLmmVmju7eltmV7ivr7M/3UzG3lxVXmI/TutbsQ\neG8FMxdUOlhoK6mV37KrzUFYze9LFP/FYbzI9k7v4+4DmWYw0H9rAyF7n7O9sKPBmHsPi1PAfRf4\nrplNApYS5nI+jpAbn/4MPgr4u5kt7c/UkCIy8MZ7D9NoUWzUefYnw2xe5u79PMeefRxPijsh9f9N\nwPsrnNJre6aGOytz3jvoPevJv5rZUdtx/NEum8O5Q9Fa2yhO95b+yX+3UnVL6O/fZiWyy1wvHoRz\nDLYx/R7m7s3ufq27f9XdjyUsgf0lwiDVvAOA9w1H+0QkoeB4dCiWF5fNx1tO7/lvl/bzHNmp2yqd\nf7ZSY/Vn3vQH+E3u3lLhfts0VZ6ZHQp8J7VpA2F2jPeQPMbVwO9i6sV4lJ3TuNhUbNsrPSB2jziI\ntlKHDnRj2Po+j8YvR9n3nP4+b+m/qR7CwjEjlruvc/dvsvWUhm8YjvaISELB8eiwV+Z2c3YBjPgz\nXPrDZXczy06NVJSZ1RACrMLh6P80Sn3J/kxY6RRnI136p9yKBhDFtIh39vdEcaXEC+mdU/s+d3/G\n3a8kzDWcN58wddR4dC29v4ydPAjnuDX1/yrgrZXsFPPBT+qzYj+5+wuEL8h5S81sewaIZqX/fgfr\nb/dOeuflvrnUvO5ZZnYAved5Xu7uWwaycYPoIno/vouGqR0iEik4HgJmtqOZ7bgdh8j+zHZ9iXq/\ny9zOLgtdysfovezsFe6+vsJ9K5UdST7QK84Nl3SeZPZn3VLeTYWLfmT8N2GAT9657v6X1O0v0vtL\nzRvMbDQsBT6gYp5n+nE51MwGOiD9beb2v1QYyL2P4rniA+G8zO3vD+AMCOm/30H5242/uqRXjpxB\n8Tndi8nm2P9mQBo1BOK0i+lfnCpJyxKRQaTgeGgsJiwB/R0zm91n7RQzeytwRmZzdvaKvP+l94fY\nG83sIyXq5o9/KGFmhbQf9aeNFXqS3r1Cxw3COYbDA6n/LzGzY8pVNrOlhAGW/WJmH6R3D+g9wGfT\ndeKH7Nvp/Rr4rpmlF6wYL75G73Sk8/t6brLMbK6Zva5Ymbs/CNyQ2rQn8P0+jrcPYXDWYPkfYG3q\n9iuBH1QaIPfxBT49h/ChcXDZYMi+93w9vkeVZGZnACemNrUQHothYWZnxBULK63/WnpPP1jpQkUi\nMkgUHA+dCYQpfVaa2SVm9tZyb6BmttjMzgP+QO8Vu+5m6x5iAOLPiJ/KbD7XzL5nZr1GcptZjZmd\nTlhOOf1B94f4E/2Aimkf6V7NY83sF2b2CjPbI7O88mjqVc4uTfwnM3tjtpKZNZrZWcA1hFH46yo9\ngZntB/wwtakZOKXYiPY4x/H7U5vqCMuOD1YwMyK5+72EwU55k4BrzOxHZlZyAJ2ZTTOzk83sIsKU\nfO8pc5ozgfQqfx81s99mX79mVhV7rq8nDKQdlDmI3b2V0N70l4JPEO734cX2MbN6M3u9mf2J8iti\n/jP1/0nAZWb25vg+lV0afXvuwz+BX6c2TQT+YWb/L6Z/pds+xcy+C/w4c5jPbuN82gPlc8Az8bXw\nplLLWMf34PcQln9PGzW93iJjlaZyG3q1hNXv3gRgZo8DzxCCpR7Ch+c+wIIi+64ETiq3AIa7n29m\nRwPvjZuqgM8AZ5rZrcAawjRPh7L1KP6H2LqXeiCdS++lff9fvGTdQJj7czQ4nzB7xB7x9kzgUjN7\nmvBFpp3wM/RhhC9IEEann0GY27QsM5tA+KWgMbX5w+5ecvUwd7/YzH4OfDhu2gP4OXBqhfdpTHD3\nb8dg7YNxUzUhoD3TzJ4iLEG+gfA3OY3wOC3qx/EfMLPP0bvH+J3AKWZ2G/AsIZBcQpiZAMKvJ2cx\nSPng7n6VmX0G+A+S+ZmPA24xszXA/YQVCxsJeekHkMzRXWxWnLxfAJ8GGuLto+OlmO1N5fgYYaGM\n/OqgU+P5/83M7iB8uZgDHJ5qT96F7v6z7Tz/QGggvBbeCbiZPQo8RTK93FzgYLaefu4v7r69KzqK\nyHZScDw0XiQEv8WmlNqdyqYsuhr4QIWrn50ez/lJkg+qesoHnDcBJw5mj4u7X2RmhxGCgzHB3Tti\nT/G1JAEQwMJ4yWomDMh6uMJTnEv4spT3S3fP5rsWcxbhi0h+UNa7zOwadx9Xg/Tc/UNmdj9hsGL6\nC8YuVLYQS9m5ct39B/ELzNdJ/taq6f0lMK+b8GXwn0XKBkxs0ypCQJnutZxL79dof47ZZGanEYL6\nxj6qbxd33xxTYP5M7/SrmYSFdUr5CcVXDx1uRhhUnR1YnXURSaeGiAwjpVUMAXe/n9DT8XJCL9Nd\nQK6CXdsJHxCvd/fjK10WOK7O9CnC1EZXUXxlprwHCT/FHj0UP0XGdh1G+CC7k9CLNaoHoLj7w8Ah\nhJ9DSz3WzcCvgAPc/e+VHNfM3kHvwZgPE3o+K2lTO2HhmPTyteea2bYMBBzV3P0nhED434FVFezy\nKOGn+iPcvc9fUuJ0XEcT5psupofwd3iku/+qokZvJ3f/A2Hw5r/TOw+5mLWEwXxlAzN3v4gwfuKr\nhBSRNfSeo3fAuPtG4BWEntf7y1TNEVKVjnT3j23HsvID6UTCY3QbvdNuiukhtP8Ed3+7Fv8QGRnM\nfaxOPzuyxd6mPeNlNkkPz2ZCr++DwENxkNX2nmsq4cN7HmHgRzPhA/H2SgNuqUycW/hoQq9xI+Fx\nXgXcGHNCZZjFLwgHEn7JmUaYRmsj8AThb66vYLLcsfcgfCmdS/hyuwq4w92f3d52b0ebjHB/9wVm\nEVI9mmPbHgRW+Aj/IDCznQmP646E98oXgdWEv6thXwmvFDNrAPYj/Do4h/DYdxEGzT4O3D3M+dEi\nUoSCYxERERGRSGkVIiIiIiKRgmMRERERkUjBsYiIiIhIpOBYRERERCRScCwiIiIiEik4FhERERGJ\nFByLiIiIiEQKjkVEREREIgXHIiIiIiKRgmMRERERkUjBsYiIiIhIpOBYRERERCRScCwiIiIiEik4\nFhERERGJFByLiIiIiEQKjkVEREREIgXHIiIiIiKRgmMRERERkUjBsYiIiIhIpOBYRERERCRScCwi\nIiIiEik4FhERERGJFByLiIiIiEQKjreTmXm8LBrutoiIiIjI9lFwLCIiIiISKTgWEREREYkUHIuI\niIiIRAqORUREREQiBcd9MLMqMzvTzO4zszYze8HM/mpmh1ew78Fm9hsze9bMOsxsnZldaWZv7WO/\najP7pJndnzrn38zsyFiuQYAiIiIig8DcfbjbMGKZWQ1wMXBi3NQNNAPT4v9PAf4Uy3Zx96bUvh8E\nfkbyBWQjMBmojrd/A5zm7rnMOWuBS4HXljjn22ObtjqniIiIiGwf9RyX9zlCYNwDfBaY6u7TgV2B\nq4Hzi+1kZkeQBMYXAwviftOALwEOnAp8vsjuXyIExjngk8CUuO8i4O/ALwbovomIiIhIhnqOSzCz\nicAaQm/vV939nEx5PXA3sE/cVOjFNbNrgJcDNwPHFOkd/hYhMG4G5rn75rh9cjznROCL7v6tzH61\nwJ3AgdlzioiIiMj2U89xaa8iBMYdwA+yhe7eAfx7druZzQCOize/nQ2Mo38D2oFJwOsy55wYy35U\n5JxdwPf7dS9EREREpGIKjks7JF7f6+6bStS5oci2gwEjpE4UKyceb1nmPPl98+dsLnHOG0u2WERE\nRES2i4Lj0mbF69Vl6qwqs9+mMgEuwMpMfYAd4vWaMvuVa4+IiIiIbAcFx4OnfrgbICIiIiL9o+C4\ntBfi9U5l6hQry+/XaGazipTnzc/UB1gXr+eW2a9cmYiIiIhsBwXHpd0drw8ysykl6hxTZNs9hHxj\nSAbm9WJmU4ElmfPk982fc1KJcx5VYruIiIiIbCcFx6VdBWwmpEd8IltoZnXAp7Pb3f1F4Lp483Nm\nVuwx/hzQQJjK7fLMOVti2UeLnLMGOKtf90JEREREKqbguAR3bwG+G29+xcw+ZWaNAHHZ5kuABSV2\n/zJh4ZBDgAvNbH7cb5KZfQE4O9b7Tn6O43jOLSTTxn0jLludP+fOhAVFdhmYeygiIiIiWVoEpIzt\nXD76Q8BPCV9AnLB89BSS5aN/C7y3yAIhdcBfCXMeZ8/ZFc/551i2k7uXm9lCRERERPpBPcdluHs3\n8Fbg48D9hEA1B1xGWPnuz2X2/S/gUOB3hKnZJgGbgH8AJ7n7qcUWCHH3TuAEQsrG8ni+bkLAfDRJ\nygaEgFtEREREBoh6jkcZM3sFcDXwtLsvGubmiIiIiIwp6jkefT4br/8xrK0QERERGYMUHI8wZlZt\nZheb2WvilG/57fua2cXAqwm5xz8atkaKiIiIjFFKqxhh4iDArtSmzUANMCHe7gHOcPfzhrptIiIi\nImOdguMRxswM+DChh3h/YDZQCzwH/BP4obvfXfoIIiIiIrKtFByLiIiIiETKORYRERERiRQci4iI\niIhECo5FRERERCIFxyIiIiIiUc1wN0BEZCwys6eAKUDTMDdFRGS0WgRsdvddhvKkYzY4fs1eOztA\nV0dHYVtVQx0A+x22FIBJ06YVyppWrABgywsvAFCd6ymUtXWGaYe9J8zs0dHZWSjrjMfvjpN+eFXS\nGe894RhhdjaobahP2lJXG7bVNiTnaQvHbe8I5+vsyRXKqutD2ydOntrrGmBiQzh+Dd3hOO3JNMkb\nXtwEwPPxekvqmO3NrQBsams3RGSgTWlsbJyxePHiGcPdEBGR0WjFihW0tbUN+XnHbHCc8xjc1iR3\nccLM6QDsesB+AMyZt6BQNn/+fADuvPZ6ADaufT7ZryYEpl1dMUgmiSXzgW9NdwhMSU2NZ/HcPTHQ\nriEJuC0Gsp5LnvTZc3YAoDvW37h2deo8oV77phCMP/vcqkJZdW04T00+4G6YUChrmDQZgCm14T6s\nffyx5H5VVyMig6Zp8eLFM5YtWzbc7RARGZWWLFnC3Xff3TTU51XOsYiMe2Z2vZlp0ncRERm7Pcci\nIsNt+apNLDr7suFuhkhRTd85YbibIDIijdnguLEh5PK2dCU5xx2EfNstzS0AHDBjdqFsjwULAeiK\n+cWX/vGPhbKJsYO9tjakLVSn0hHMGgHo7gn75XLdhbKemHNcVR32b21tL5RVVYVjHXzYSwvbDlh6\nGACTpoZ84t+d/8tC2QP33ANAXUyhaKxKOrkaa0Mbch7atWVTS6HshfWbQ5trQ9mcCY2Fsgl1SQ60\niIiIiCitQkRGGTNbamYXmdkqM+swszVmdpWZnZyqc5qZ/cnMnjSzNjPbbGY3m9mpmWMtiukUx8Tb\nnrpcP7T3TERERoIx23NscdBcdVXSy+txFod6D72702cmg8h32mUvAA7oCr27GzatLJTdevWtYf84\n+K7Kku8Uua5wrPq6MOCtOzXvQ0scYdmVCz3WM+OAO4AjXv4KAF7++jcn7asKO69ZHQbi+ZSkZ3vV\nlnCeGbGztzEOsAPo7Ag9xbF51DUkvcM1sV5PnKWiMTU7Ri41I4fIaGBmHwB+BuSA/wMeA2YDLwE+\nAvwhVv0Z8CDwT2ANMBN4HfBrM9vL3b8c620EvgqcBiyM/89rGsS7IiIiI9SYDY5FZGwxs32AnwKb\ngaPc/cFM+fzUzf3c/YlMeR1wBXC2mf3c3Ve5+0bgHDM7Fljo7udsQ7tKTUexd3+PJSIiw2/MBseF\nXtSa2sK22urw/87NGwB4+qlHC2Vz9zgAgMUHL411kynWPBf2u/aKqwGYkpqvuCHOnVxroYe6vi7V\nMxvTgnffK8xdfeTLX14oW7jPQeF6t72SRsfp51Y9/Uy4Xvls0vaqUDahJj+ncWo6udjjbBbqtDZv\nLpS1deTlcFzUAAAgAElEQVRindDb3T0xaXtre5KPLTIKnEF4z/p6NjAGcPeVqf8/UaS808x+Arwc\neAXwq0Fsq4iIjFJjNjgWkTEnP3r1ir4qmtnOwOcIQfDOQGOmyryBapS7LynRhmXAIQN1HhERGRoK\njkVktMgvabmqXCUz2xW4A5gO3AhcBWwi5CkvAt4LaKoWEREpaswGx/mV6yCZ8iwXB8blB6JZd7LM\n8qbn1wIwZ2FYNa96YjIYbtLU8Jk8ccokALo6kqnSGmKaQ3Mc7JdLVpZm3s4hBfL4N7wGgN32TTqR\nZi7YH4AJjUmH1sqnnwKgqSkMyHvm6aZC2cT6kNoxeUJI22htTqaFq7FQlh8oWFOdPK1dHpei7g73\nvaU1WT46pyUPZHTZGK/nAQ+XqfcpwgC80939gnSBmb2DEByLiIgUNWaDYxEZc24jzErxWsoHx7vH\n6z8VKTumxD45ADOrdvdciTr9tt+8qSzTQgsiIqPKmA2Oe3pCt2h9YzJAriv2FPdUTwBg/q77FMom\nx0VDvD0MxJs0YVKhbOnhhwPQUBt6iR9f8UChrLttCwCbNofe5IaJUwtl+x5wMAAdcUDflFk7F8pq\np4Te6LYtLxS2bdn0PAD3PXA/ABs2bCiU7bJDOG59XMyD+tRAw7igSL4jOFeVTDVXUx+mgMsPvvOu\n5HO/xzTNtYwqPwM+DHzZzK5094fShWY2Pw7Ka4qbjgX+mip/NfD+EsdeH693Bp4awDaLiMgoM2aD\nYxEZW9z9ITP7CPBz4B4zu5Qwz/FM4FDCFG/HEaZ7Ox34o5ldDKwG9gNeQ5gH+ZQih78GOAn4s5ld\nDrQBT7v7rwf3XomIyEij4FhERg13/28zWw58htAz/CZgHXA/8ItY534zOw74BnAC4X3uPuAthLzl\nYsHxLwiLgLwd+Je4zw2AgmMRkXFmzAbHNbXhrvXkkjSC7q6QVtHRHrbNnb9LoWzajOkAbNwY0hy6\nO5IBb/N23S2UbQlpDhMmJSkN3W1hTuHO7jDIb+5OyQxRC3cO+9XUh5XxGlIr3nV2hzSHlub1hW1r\nXwgD8e68404ApjckT8+UxnDOls0hjaOrI1ndrp0wCrCuPqaGpLIl6qrDjQn5xyM1CK8nNVeyyGjh\n7rcCb+2jzi2E+YyL2eqFH/OMvxAvIiIyjinpVEREREQkGrM9x1U14a6ZJ12lNVVhMNtTDy4H4OYr\nLyuUveS4owBYuTqsSjcxNcXaDvMXAbB3XAXvmclTCmXdraHneN7OYaW7KZOSAYDr1oaV7qbOmtmr\nTQBVFnqvJ0ydXtj2zJrQM/3cqjAwLz8ID2DqhDAt66bO0PvtPcmccc3t4f85D4PvGmqTNkzoCdss\nFzrLOj3pcVbPsYiIiEhv6jkWEREREYnGbM9xdXXo5fV0z3HsuW3ZHNYS+M1/nVsou+vO6wA49Kgw\nDerhRx1fKMt1hv1mzgwLhFT1JDnHExrqAJg6I+Qau3UXyp7bEM7zWNNjABw0a06hrHZCnMqtM/l+\ncu11NwPQFXOj6+omF8ry2xrilHOWeuq6e0JvcG1NOFZtddIj3FMV/m9x6req1Mof7R1JW0VERERE\nPcciIiIiIgUKjkVEREREojGbVlFlIZ0gl0qrqK0NqQUNMcUglxrU9twzTQA89NCOAKzenBzrZUeG\nwXo7zw9pFTUNSbpD/eSwkl5HV5iaraomOd+EySF1Yvmyu8L5WpPp4aonhUF6v//fiwrbLr/4EgDm\nzQoD8aZMnlAo64or3MVxdVRNqEva0BAG61XXxPucmr6uriakYbS0tOXPXCjrdKVViIiIiKSp51hE\nREREJBqzPccWe47zvcWQDMjL9YTvBNaTfDfYa+/9AWhaHQbR3Xj/dYWypYctDfvXh17X6Q0zCmU9\nuTBQ7r67bg/7P/1koWz6tNCr/OTDDwOw4s7bk/3qQo/uvbfcWNh24O7zAairCj26na1thbLqqprY\nhtp4O7lfPR56itvaWsLtnqTnmNhz3tERep47e5KnPD9oUUREREQC9RyLiIiIiERjtuc430ucWi25\nkIvbEHuA2zuTBTGckMP7xte+EoB1za2Fsnn5JaF7wn5VqaOuf34NAKtWhWWgb7j+7kJZtYfE5Z1m\nhdzhhXMXFcrmztkx1tlY2DZ7Zth2x033ANC5JcmJzq/73NUdepVr6pOnLt9P3NkVyjo6k1zi7tjU\nXHXoqd4Sc5cBqqr03UhEREQkTdGRiIiIiEik4FhEREREJBqzaRX5AXnpFfLy/891hUQEzyVpFU1P\nhkFzrz/ptQAcucf+hbKeXHP4T1dIq+i2ZBq1idPC4Lwd5swGoLo6Od/RR7wMgI3rngl1ZkwrlM2I\nq+VNmTarsG2X3XYHYM2qFwB4cNnDhbKZ08N58gPr8tfp/9fWhqezoytJq8iPzcsPvjNPBusl6+iJ\niIiICKjnWERGGTNrMrOm4W6HiIiMTWO255jYc1yTmq4s35tclQu9u7WpBTFat4TBc08+sQKAtu5N\nhbK5c3YFoCu3BYD6ximFsuqGcIyDD14MwOwdPlAou/zSPwKwbnUTABMb9ymUdcbVPObstHth2yGH\nHg5Aj4ce7UcfeqJQtqU1DBBsyC/4kRoUaF1hOrnujjCALz19XW1+6rfOUGfH2uQpV8+xiIiISG9j\nNzgWERlmy1dtYtHZlw13M6SIpu+cMNxNEJERSmkVIiIiIiLRmO05zqdQFJMfmFdlyXeDzjg38LJb\n7wPg5L0OLJTddvcD4T9xnuO9dt+tULZh/UoAFu21HwD/939/LpTdG1fEW7hTGKxXk0p3mDgppGYc\ntOSwwrbuOD5w9pwwSO8tJ721ULbigUcBeP6FtQC0vPBCcoeqw/3ID7qrra5PiupiGkZtSLnojukV\nAC2tLYiMRBb+gD8KnAHsBqwHLgG+WKJ+PXAW8K5Yvxu4DzjX3f9Q4vgfBz4E7Jo5/n0A7r5oIO+T\niIiMDmM2OBaRUe2HhOB1DXAe0AWcCBwG1AGFFXLMrA64EjgGeBj4CTABeBtwkZkd5O5fyBz/J4TA\ne3U8fifwRmApUBvPVxEzW1aiaO9KjyEiIiPHmA2Oy03lZhanNUsNTiMO0qNmEgA33fFIoeg3vw8d\nT3V1oYf2Yx98d6Gs9YVVAFx95Y0AdCSzw/HWt5wIwAuxzrQdJhXKpk4J5851tRe2/ePKGwCY2Bh6\nexcsWlgo2zX2Vre3h/oPLH+gUHbttWG/5tYwpVtDqg25qhBDeLxOj8LLVSU92SIjhZkdQQiMnwCW\nuvuLcfsXgeuAucDTqV0+TQiMrwDe6O7dsf5XgTuAz5vZ39z9lrj9KEJg/ChwmHtYptLMvgBcDeyU\nOb6IiIwjyjkWkZHm9Hj9zXxgDODu7cDni9R/H2Gl+E/lA+NY/3ng6/Hm+1P135s6/sZU/c4Sxy/L\n3ZcUuxB6sUVEZJQZsz3HuVxY7CKde1xYCCPfc5wqq4odx63NYbq2h1ckPcctLeHzdmNL6H1tWrOu\nUHbPzXcC8PgjjwPw8bM+ViibNz/kDu+3355AMg0bwD13htzm66/7R2FbXVVo8wH7hSnfmlsKn9tM\nnRoWAZk6PfQ+H3X0EYWy2XPCgiJX/F841qqnVqfuV8xHrrF4n5NFQGobGhEZgQ6J1zcUKbsJKLyI\nzWwysDuwyt2LBaPXxuuDU9vy/7+pSP3bCPnKIiIyTqnnWERGmqnxem22IPYMrytSd02JY+W3T0tt\nK3f8HGFwnoiIjFMKjkVkpMmvwLNjtsDMaoAditSdU+JYczP1ADaXOX41MLPiloqIyJgzZtMqksF3\nqdSJqvBdwPOry1kycq2+NqRarH8upCTMXJAMnps+NUy7tntMj3hgxaOFsmtvug2A0955EgB7L05W\nvKuNA/4mTQrpC48+mqx4d9ut9wDQ2Z4MGGztDJ/fzS0htWPf/ZLp5KZMDp1dHe1h0N26dUnn2W67\nLgDgrae8GYBfXnBRoWz9utAJ1lgdBt91p74OvfntpyIyAt1NSK04BngyU/YySJa2dPctZvYEsKuZ\n7eHuj2XqH5c6Zt49hNSKlxU5/ksZwPfF/eZNZZkWmxARGVXUcywiI80F8fqLZjYjv9HMGoBvF6l/\nPmEelu9ZfkBBqL8D8OVUnbxfpY4/NVW/DvjWdrdeRERGtTHbc1xXVwdkpnLrCT3FXhV6k2tqku8G\nVT1hW2d3GIuz5qmkQ2l6Y/i8XXbzPwHY0rq5UHbKSW8B4PVveDUAi3ZJpl979NHQw9wVjzlzZvJr\n7VFHh8U/NqR6gJ9tegqATRvCFKtbNm8plM2eFX5JzuXCoMAdZk0vlHV1hG2z5objLznypYWyv10S\nlq7NtYY2HP6qpBfr/Z/8DCIjjbvfbGbnAmcCy83sYpJ5jjewdX7xvwOvjeX3mdnlhHmOTwJmA991\n95tSx7/BzM4DPgg8aGZ/isd/AyH9YjXQg4iIjEvqORaRkegThOB4E2EVu3cQFvp4JakFQKAwBdvx\nJKvnnUmYru0x4J3u/rkixz8D+BTQDHwYeCdhjuPjgSkkeckiIjLOjNme43yucT7PGKAmTuXWmQu9\nqN1dybRm+czk2KnMhKqkrKc5fE7WbglTrh60x66FslNPCT3Hc+aFadtaWpPe3ikzQu/urDnzAGjd\ntKFQVpVrA2Dt5CmFbQt32yucx0Jv9+ZNKwtlm5pD7nCu22Pbk/vV2pW/DvnIe+2/V6HsoYdDnvNz\na0O7TvrgJwtl9VMLvyiLjCgefvL5cbxkLSpSv52QElFRWoS79wA/iJcCM9sDmASs6F+LRURkrFDP\nsYiMO2Y2x8yqMtsmEJatBrhk6FslIiIjwZjtORYRKeOTwDvM7HpCDvMc4BXAfMIy1H8cvqaJiMhw\nGrPBcVV16BTq6UnG1fTEKdzyK+X15NJ7hHyKwvC9XFehZEpjAwCLd9k57F+XPGxrVz0LwE4LwoC5\nuvpk1bkJU+O6AzXhfB1dyTE7usKZdtx5t8K2+TsvAmDlk2F1vhc3JGkVLa2tADS3tMY701AoW7Ou\nBYDWrpAuUtswoVB2wEsOB+A1CxYDsHBRMmCwpzs+NjX6AUHGnX8ABwKvAmYQVsV7FPgR8ENPj+QV\nEZFxZcwGxyIipbj7NcA1w90OEREZecZscJzvL+721IxMXlW0DkBnZxjMVmwgX3dcLKQrDuTraW4p\nlLXF/09oDIuGNLcnZfX5Y7c2h/3bksF61XWhdNbsZGGvhgkTAWhpbQdg4sRkurb6WD+XC+1b9Wyy\n8u2G9aG+14Re686eZDD/jgsWAXDEMccAUOtJ73Vbc6zXkAwKFBERERnP9Hu6iIiIiEik4FhERERE\nJBqzaRUd3SFlIJcakJfLjLHJp1AAVNWGhyKXC6P02mOaBUB1bf5hCvt3trUXyp55sgmA/Gnq6usL\nZbmuUG/D82FBr9aNGwtlnh8M2Nlc2LZ8WVhRr85C+sacRcl8xVYV7s+kjjDncktz0gavCukY67eE\nwXobWpPz7BjnTp44czIAG1P75eK8yPN3UFqFiIiICKjnWERERESkYMz2HBf6iFO9w91x7rb8YLuq\nVFmhF9njdVJEdxyIl69fU1NbKFt2+x0ATNlhBgAnvu3EQtmzTz4JwNNxarYaS/Vix5Xunln5bKoN\n4bhLX3JYvA/VhbK6OD1bw6Qw8G+fqclAvpUrVwHQ/NCDAMxqTHqC995rTwDyw/DWNyc94lPqUndS\nRERERNRzLCIiIiKSN2Z7jvMLfaSj/3w+cb6XOD3Pf7k5/6tiN3JVXG3WapIe19b2kMN79WVXAjA1\nTscG0ONtADS3vAhATV2ycMfKVXEqtphfDLD//gcB0BaP2TAlWcyjfmroMbbacIz6VK/yntPClG91\ndXXhfK3J0zpz+nwANrSFXuvNza2Fsrlx4RIRERERCdRzLCIiIiISKTgWkRHFzJrMrGm42yEiIuPT\nmE2r6OgMU5/V1iaD5/LpFF1dYXhad3f3VmWlbkOSltGTmh4un42xafMmAG666aZC2aFLDwGSle42\nbExSGu65JwzWO/xlBxa2TZsRBvX1VIXj1zTWJSePz1R3dzhGe1ey0l1DHCA4d+FuAKxen6SIrI+r\n4NVODSkaLa1JG6qr9N1IREREJG3MBsciIsNt+apNLDr7siE/b9N3Thjyc4qIjBVjNjju7t66dzg/\nhVt+W74nOC2/raYmeWjyvcgWB+Z1dSe9tvmu46rqcOympqcKRfMXhMFwixYtBGDunNmFsrnzw/Rr\nVp0M0tvSGnqMNz6xOtTpSBbsmD8v7NsdF+7oamsplLV2xvtaE3uebXqhrKY2DNxbtyZMGffIww8X\nyg7ec+et7r+IiIjIeKbf1UVkyFnwMTN70MzazWyVmf3YzKaW2ecdZnadmW2M+6wwsy+ZWX2J+nub\n2QVm9qyZdZrZWjP7nZntVaTuBWbmZrarmZ1pZvebWZuZXT+Ad1tEREaBMdtz3NMTenR7T9cWri2/\nCEiRqdzy112pnN58z3F17E1OT/pWyD+O+6V7o++66y4Anngq5BfvtGBhoWzRbuH/9y+/t7Bt2V3L\nAdgcc5OPP35poeyIlx4AQGNcuKOjeXOhrLUl/L+tehoAU3c5olDWUBvqP/nICgBmTJtcKJs0JZl2\nTmSI/RD4OLAGOI+wTs2JwGFAHdCZrmxm5wOnAyuBPwEbgZcCXwdeYWbHu3t3qv5rgD8DtcBfgceB\n+cBbgBPM7Dh3v7tIu/4TOAq4DLgc2PrnJRERGdPGbHAsIiOTmR1BCIyfAJa6+4tx+xeB64C5wNOp\n+qcRAuNLgHe5xwnEQ9k5wFeAjxICW8xsOvB7oBU42t0fStXfD7gN+AVwSJHmHQIc7O5PFSkrdX+W\nlSjau9JjiIjIyKG0ChEZaqfH62/mA2MAd28HPl+k/ieAbuB96cA4+jqwHnhXatt7gGnAV9KBcTzH\ncuC/gYPNbJ8i5/pufwJjEREZe8Zsz3HOt14Fzyz/XSBs6+5JfjHN17Ka6q32y/8vHpKcJ1O55VM0\nqnvCfu2dHYWy/Q/eD4A3vv0NAPz9qmsLZXfcHlIunn7iyaTN7SGVo6sj/KJ82+3JVG677x3SMKot\npFy0bt5SKKvOhXN6Y2jDjImNhbJn1zcD0DA5rIa33y4LkvtVnb8fyWp7IkMg32N7Q5Gym0ilMpjZ\nBOBAYB3wyWJTLAIdwOLU7cPj9YGxZzlrz3i9GHgoU3ZHuYYX4+5Lim2PPcrFeqdFRGQEG7PBsYiM\nWPlBd2uzBe7ebWbrUpumAwbMIqRPVGJmvP5AH/UmFdn2XIXnEBGRMWrMBsf5/qX04Ln8ILseDx1T\nnuoBrq6u7nVdlVogI9+LnB98V2wKOI8DAI2kZ+veu8Ngu5rYo7v8wUcKZQ/f/xgAdTXJIiV1teHp\nqInnfvShpP4/r74FgAP22wWAtpaNSdtjD/jE2TsC0NKc3K9cT5gqburUuaFuTTKw/4V14RftOTvt\nuNX9ERlEm+L1jsCT6QIzqwF2IAy8S9e9x90r7YXN73Ogu9/fz7Z531VERGQsG7PBsYiMWHcT0g2O\nIRMcAy8jlefj7s1m9iCwr5nNSOcol3Eb8FbCrBP9DY4H1H7zprJMC3KIiIwqGpAnIkPtgnj9RTOb\nkd9oZg3At4vU/z5herfzzWxattDMpptZulf5l4Sp3r5iZkuL1K8ys2O3vfkiIjKWjdme454i8xXn\n5XJhOtT86nGQzGWc1ElSJ/KpFnnplIv88bPzJANsXh8GzV37t+sB6O5O0h2m1k/In7iwLT9AcOas\nWQDsve/+hbLn14U0zMeeCGmak1PZkhPjs7hh5ZpwvxYkKRc99SGNomVLGJg3fUqSVtFQnwz4Exkq\n7n6zmZ0LnAksN7OLSeY53kCY+zhd/3wzWwJ8BHjCzK4EngFmALsARxMC4g/H+uvN7G2Eqd9uM7Nr\ngAcJKRMLCAP2ZgINiIiIZIzZ4FhERrRPAI8S5if+EGE6tkuALwD3ZSu7+0fN7ApCAPxKwlRtLxKC\n5O8Bv8nUv8bMDgA+A7yakGLRCawGriUsJDLYFq1YsYIlS4pOZiEiIn1YsWIFwKKhPq+lezpFRGRg\nmFkHIX96q2BfZITIL1Tz8LC2QqS0A4Gcu9f3WXMAqedYRGRwLIfS8yCLDLf86o56jcpIVWYF0kGl\nAXkiIiIiIpGCYxERERGRSMGxiIiIiEik4FhEREREJFJwLCIiIiISaSo3EREREZFIPcciIiIiIpGC\nYxERERGRSMGxiIiIiEik4FhEREREJFJwLCIiIiISKTgWEREREYkUHIuIiIiIRAqORUREREQiBcci\nIhUws/lmdr6ZrTazDjNrMrMfmtn0fh5nRtyvKR5ndTzu/MFqu4wPA/EaNbPrzczLXBoG8z7I2GVm\nbzOzc83sRjPbHF9Pv9nGYw3I+3EpNQNxEBGRsczMdgNuAWYDlwIPA0uBTwCvMbMj3X19BceZGY+z\nJ3AtcCGwN3A6cIKZHe7uTw7OvZCxbKBeoylfLbG9e7saKuPZl4ADgWZgJeG9r98G4bW+FQXHIiJ9\n+ynhjfjj7n5ufqOZfR84C/gm8OEKjvMtQmD8fXf/dOo4Hwf+M57nNQPYbhk/Buo1CoC7nzPQDZRx\n7yxCUPw4cAxw3TYeZ0Bf68WYu2/P/iIiY1rspXgcaAJ2c/eeVNlkYA1gwGx3bylznEnA80APMNfd\nt6TKqoAngYXxHOo9looN1Gs01r8eOMbdbdAaLOOemR1LCI5/6+6n9mO/AXutl6OcYxGR8o6L11el\n34gBYoB7MzABeGkfx3kp0AjcnA6M43F6gCsz5xOp1EC9RgvM7BQzO9vMPmVmrzWz+oFrrsg2G/DX\nejEKjkVEytsrXj9aovyxeL3nEB1HJGswXlsXAt8G/gO4HHjGzN62bc0TGTBD8j6q4FhEpLyp8XpT\nifL89mlDdByRrIF8bV0KvAGYT/ilY29CkDwNuMjMlBMvw2lI3kc1IE9EREQAcPcfZDY9AnzBzFYD\n5xIC5b8PecNEhpB6jkVEysv3REwtUZ7fvnGIjiOSNRSvrV8QpnE7KA58EhkOQ/I+quBYRKS8R+J1\nqRy2PeJ1qRy4gT6OSNagv7bcvR3IDySduK3HEdlOQ/I+quBYRKS8/Fycr4pTrhXEHrQjgVbgtj6O\ncxvQBhyZ7XmLx31V5nwilRqo12hJZrYXMJ0QIK/b1uOIbKdBf62DgmMRkbLc/QngKmAR8NFM8VcJ\nvWi/Ts+paWZ7m1mv1Z/cvRn4dax/TuY4H4vHv1JzHEt/DdRr1Mx2MbMZ2eOb2Szgl/Hmhe6uVfJk\nUJlZbXyN7pbevi2v9W06vxYBEREpr8hypSuAwwhzbj4KHJFertTMHCC7kEKR5aPvABYDJxIWCDki\nvvmL9MtAvEbN7DTg58BNhEVpXgR2Bl5HyOW8Czje3ZUXL/1mZm8C3hRvzgFeTXid3Ri3rXP3z8S6\ni4CngKfdfVHmOP16rW9TWxUci4j0zcwWAF8jLO88k7AS0yXAV919Q6Zu0eA4ls0AvkL4kJgLrAeu\nAP7V3VcO5n2QsW17X6Nmtj/waWAJsBMwhZBG8SDwB+C/3L1z8O+JjEVmdg7hva+UQiBcLjiO5RW/\n1reprQqORUREREQC5RyLiIiIiEQKjkVEREREonEXHJtZk5m5mR073G0RERERkZFl3AXHIiIiIiKl\nKDgWEREREYkUHIuIiIiIRAqORURERESicR0cm9kMM/u+mT1lZh1mtsrM/tvM5pbZ5zgz+7OZPWdm\nnfH6EjN7eZl9PF4WmdliM/tfM3vWzLrM7C+perPN7HtmttzMWsysPda7xcy+ZmYLSxx/lpl928we\nMLPmuO9yM/tmsaVARURERKS4cbcIiJk1AQuBdwPfiP9vBaqB+litCTikyIpC3wC+GG86sImwpGZ+\nhaHvuPvni5wz/yC/h7A05wTCqkO1wJXu/qYY+N5KWDELIAdsBqaljn+Gu/88c+yXEZZPzAfBnUAP\n0BBvP0tY7vORMg+LiIiIiDC+e47PBTYQ1uCeCEwCTgQ2AouAXkGumb2dJDD+MTDb3acDs+KxAM42\ns1PLnPOnwJ3A/u4+hRAkfzqWfYUQGD8OHA3UufsMoBHYnxDIP5dp00Lgr4TA+GfAHrH+xLjPVcAC\n4M9mVl3JgyIiIiIyno3nnuO1wL7uvj5T/mng34Gn3H3XuM2AR4HdgQvd/R1Fjvs74B2EXufd3L0n\nVZZ/kJ8E9nP3tiL7PwQsBt7u7hdVeF9+A7yL0j3WdYRg/ADgJHe/uJLjioiIiIxX47nn+LxsYBzl\nc4B3MbOJ8f8HEQJjCD24xXw1Xi8Clpao8+NigXG0OV6XzHdOM7MJwEmEFIrvF6vj7p1APiA+vpLj\nioiIiIxnNcPdgGF0Z4ntq1L/nwa0AIfE2y+4+4PFdnL3R8xsFTAv1r+tSLVby7TncuAw4N/MbA9C\nUHtbmWB6CVBHyH1+IHRuF9UYrxeUObeIiIiIML57jrcU2+ju7ambtfF6VrxeRXkrM/WzXiiz778B\n/0cIeD8CXAtsjjNVfNbMpmXq53uYDdixzGVKrDehj7aLiIiIjHvjOTjeFg19VykrV6rA3Tvc/UTg\ncOC7hJ5nT91+1MwOTO2Sf+42ubtVcDl2O9suIiIiMuYpOK5Mvse3r9SE+Zn6/ebut7n759z9cGA6\nYZDfM4Te6F+kqq6N11PMbOq2nk9EREREEgqOK3N3vJ5oZkUH25nZnoR843T97eLuLe5+IfDBuGlJ\napDgXUA3Ia3iNQNxPhEREZHxTsFxZe4lzD8M8IUSdc6J103AHf09QZx2rZT8oDwj5CTj7luAP8Xt\nXzOzyWWOXWNmk/rbJhEREZHxRsFxBTxMBv2lePNEMzvXzGYCmNlMM/sRIf0B4EvpOY77YbmZfcvM\nDs0HyhYsJVlk5M7Mqn1nAy8CewK3mNlrzKw2te8eZvYp4GHgJdvQJhEREZFxZTwvAnKcu19fok7+\nQTJeOMIAACAASURBVNnF3ZtS29PLR/eQLB+d/5LR1/LRvY6XqbMxHgvCwL1NwGSSGTPWAa9w9/sz\n+x1KmJt5p7ipizBn8mRiL3N0rLvfUOzcIiIiIhKo57gf3P1LwCuASwnB6iRgPWEKtlcWC4z74UTg\n28DNwOp47E7gfuA7hNX87s/u5O53AnsDnwNuAZoJ8zO3EvKSfwQco8BYREREpG/jrudYRERERKQU\n9RyLiIiIiEQKjkVEREREIgXHIiIiIiKRgmMRERERkUjBsYiIiIhIpOBYRERERCRScCwiIiIiEik4\nFhERERGJFByLiIiIiEQ1w90AEZGxyMyeAqYATcPcFBGR0WoRsNnddxnKk47Z4PhnP7nAAbraOwrb\ndtt1VwCann4SgEceebhQNnHiRABaWloAaGvvLJTV1YaHafOLL4TrTVsKZa3tbQB00xWOU1NXKKuu\nCh3zU6dOBcCpLpS1tIb9amqSp6C7KxyjqirUq65J6jfWNQIwYfJkALZ0tBbK2lqbAehoaw91a+uT\nsvZQz6p6wjF7kuXC3QyAv1z9d0NEBtqUxsbGGYsXL54x3A0RERmNVqxYQVtb25Cfd8wGxxvWbwDg\nheeeLWxb9/wzADz7dLh+cf36QlljQwMANfW1ALR1JMFxd2f4v3kILI0klqyysM27ugHY0tpSKJva\nEALlHefPA2Dt5uQJ7ojH7Mp1F7blw9aaqnD8XHdPoWzipBAU5zxs6+zoKpTVxmC4NQb2nbmkrKY+\ntKGnO2zr7smlzpf8X0QGXNPixYtnLFu2bLjbISIyKi1ZsoS77767aajPq5xjERkQZrbIzNzMLhju\ntoiIiGwrBcciIiIiItGYTat4/rlVva4Bnm0K+bcdHSEPuaY6ufu5mHbQ2hFSH3pSWbi5mGJhMUe3\ntra2UGbVYVtdTzhWVU2S0rDXnB0AmFwVEiaeaklSLvKH7/EkB9iqw3cVj4XVqXzkrphO4d0hDaO2\nJmlDTcyJtpiOkW47PWE/8/g9KPV1qLpa341EBtPyVZtYdPZlw90MERkATd85YbibIENE0ZGIiIiI\nSDRmg+OVq5pYuaqJ9evXFS5bmpvZ0tyMO7hDT09P4ZLryZHryRVu4xQuNTW11NTUksv1kMv10NHZ\nWbi494RL/NfW1V24rOsIl8deXM9jL66npauzcOnq7qaru5vu1MXMCr3TANXV1YVLQ309DfX1ocvZ\noKOjvXDp6uykq7OTfGH6fnV1ddHV1UV1TQ3VNTXU1dcVLj3uvXquRQZKzD++0MzWmVm7md1lZq8v\nUq/ezM42swfMrNXMNpvZjWZ2coljupldYGZ7mtlFZva8mfWY2bGxzq5mdp6ZPW5mbWb2Yjz2z81s\nZpFjvsPMrjOzjbGdK8zsS2ZWn60rIiLjw5hNqxCRYbMQuAN4Evg1MAM4BbjUzF7p7tcBmFkdcCVw\nDPAw8BNgAvA24CIzO8jdv1Dk+LsBtwOPAr8FGuH/s3fncXaX5f3/X9dZZs02kx2CJECAKLJFAXEB\nirjUh+Kj1W+/aqtgWzdUXPr9fRHsV9C6VKxV0S7WorZasdVSW0SxBbEFilpQFAg7ISQhezKT2eec\nc/3+uO/PkpMzk0kyyUzOvJ+PRzwz932f+/M5w3Hmnmuu+7rpNbOlwM8JtYVvBr4LtAErgN8Dvgik\nJWrM7HrgUmB9HLsLOAf4GHChmV3k7lk5mTGY2VjlKE7e13NFRGT6adrF8e7dofZvtZqVKysmJdJi\nOTMni5omJc6SPsvVJC7Ejz0G2iu1/M/LWFqtEvKYN/VmecUbe58EYPGSJQDMbu9I+4ZHwvhyIcsd\n9hjFrcS84mIxu4eBwTDv0FCoZVywrC/Joa5UwvNzqcqUW0IpNyuH8fmvB8Wm/c8vU+t84Gp3vyZp\nMLN/AH4I/B/gx7H5g4SF8Q+A1yQLUTO7hrC4/pCZ3eTud9XN/yLgk/ULZzN7D2Eh/j53/3xdXyfJ\n/1nD55cQFsY3Am9y98Fc39XAR4DLgD3mERGR5te0aRUiMmWeAv4k3+DutwDrgLNyzW8lJC99IB+h\ndfcthOgtwB80mH8zcE2D9sReFePdvT+/AAYuByrAW+vaidfeDrxpnGvk517d6B8hGi4iIkcYhQ5F\nZLL90t0bnTDzNPACADObDZwAbHD3RovI2+LjGQ367nP34Qbt/wp8AviSmb2ckLJxJ/Cge5Zcb2Yd\nwGnANuB9+Tz/nGFgVaMOERFpbk27OE7SD0qWpU4kxzJXY3kzz29Giz8gPR6v7NlfYKlUY5uFtkI5\nF3D35Okx5SKXtjAay8P17e4FoD1XAi4pB5cvCzcST83LtyUGBgb2mL+tNftP1xHTNSrJKXjV7HS/\nQjzCOpk7L/l6iEyyXWO0V8j+WjU3Pj4zxtikfV6Dvk2NnuDuT5nZWcDVwCuA34pdT5vZZ9z9C/Hz\nLsLu1YWE9AkREZGU0ipEZCr0xMclY/QvrRuXN2aJFXdf4+6/A8wHngdcQfg+93kz+/26OX/h7jbe\nv/16RSIi0hSaNnJcqYa/uuajo8ViqM40GjfdVWpZdNji7wlJBLhWy37+VqshHTJ2UfLsd4pk05zF\n65RqWd/cWeF6w4Mh6jsw2Jb2zZszOzwv99fnJMrdEg/1yG+ea2vvBKC9HOYcGR7K7r2QhK99j3sC\nGB0dja8r/Jxvbc0qVCUb/0QON3ffbWaPA8eZ2Up3f7RuyAXx8d4DnL8C3APcY2Z3Af8JvBb4W3fv\nM7MHgOeYWbe77zjAl7FPpxw9l3t0cICIyBFFkWMRmSrXE9IbrjXLyq+Y2QLgj3NjJsTMVpvZ3AZd\ni+PjQK7ts0ALcL2Z7ZW6YWZdZnbmRK8tIiLNo2kjxyIy7X0GeCVwMXCfmd1MqHP8emAR8Gl3v2M/\n5vs94O1mdgfwOLCTUBP51YQNdp9LBrr79Wa2GngX8LiZJdU0ugl1kV8CfBV4x0G9QhEROeI07+LY\nk013lmsKbdnu9FzqROwrxGB6NZ9WETfulWO6QrLJLS8Z3pqrHfzqM08FYM3mrQA8ti376+2sWe0A\nFLPMDoxwX5WYCjFazXXG+UulkXi9rG/XcAiIJZvuSrlCx8lrTeau5uZs9DpEDhd3HzGzi4APAG8E\n3kPYtHcfoVbxt/Zzym8BrcC5wGrC4SAbgBuAP3P3++uuf5mZ/YCwAH4pYfPfDsIi+VrgGwf40kRE\n5AjWvItjETms3H0tMOYmNnc/v0HbEKH82icmYf6fEk7OmzB3vwm4aX+eIyIiza15F8cxYlrL/Sit\nxGhrzfcu5ZZUfPNaiNoW8rVP02zIRpvkw7hyKZ6iV8zGPLFhPQBnHPssAI5ZsCDt66uF8dv7dqdt\n/UPhFDyPEWDLbSZMTtQbGh7c605q8XUkmwiHcmXb2tpa41zx9L3RrK9U3LtknIiIiMhMpr+ri4iI\niIhEzRs5TuQiwEnkODlIY49DQGLU1ZKc3GL2e0M1xmktRlqLxZbseXGK9vaQQ7xkyaK0a93OEBXe\nXVkLwNFLlqZ9y+eFTfWzctHhX/XvjpeOec+5Um7DMQ95OEZ+k0NOYO+SbEk5OoCW1nK8vxBBbsuV\nchunXKyIiIjIjKTIsYiIiIhIpMWxiIiIiEjUtGkVSZmy/Al5lUpIU6glZdv2KGXm8X9j6bNcxkEy\nrpSWcstSNUZjSkNSKq29ozPtKycb61vC8x7dkpVye+yZbeF6uVP6ekfiGQXV8Lyh4Wzz3GA8ES+5\nrXzKRZpWEdNESqXsNQ/0h7l2l0IqSHtbllbR3ta0//lFREREDogixyIiIiIiUdOGDpPNdtVKLdcW\noqiNDr/InV4bB+cOy4ib9apDIZK7eyg7hXZ293wA2tu6AHj00YfSvq7O8OXtbJkFQFsuSlxpCxvy\nrCWL5O589L546ViGrpZFh/fYPMiexV7bSmHTnadx5WyDXnIISIGwoW9oMItG1yoq5SYiIiKSp8ix\niIiIiEjUtJHj5EAMy5UrK5fLe/RVRrPIbG00RFtrMX/XPRe1JXycHC09OjKa9q084RQA3vjmdwDw\nL//yL2nfmvv/B4CewVCiraM1i9R2dIQvfdfCJWnbYzFybDGnOR/NruWizrBnTnSSa5w8Wi4nulh3\n5HW+7Fs+H1tEREREFDkWEREREUlpcSwiIiIiEjVtWgUe1v213Ea2JDWhEk+bq1Vzm/ViukGtFh73\nPHUulkiLKQr5E+iKhFSJU049DYCTnn1q2vf1r/0tAP/8j18FoFzKvtyFuKmva+68tK17bjcAO3du\nDXMXs7SHkViGrmBJmkR2d9V4r4V4ql+ptPdGO09SNXL30NYxa69xIiIiIjOZIsciMq2Y2VozWzvV\n9yEiIjNT00aOk+huvhzaSBIxHh4EoCUXfh2uhhJnyUEhkEWVLdn9Fh+tmG14q9bCnH0D/cCeh4Cc\nsPJEANo65gCwY3dvNmdPONTj/GOOTduWHX00AL27tsbrZq+nQLLBMN5d7hCQYim8ju7uEHmu5qLe\nPb298T7D56VyFlVua29HRERERDJNuzgWEZlq92/oYfkV35/q29hvaz/1qqm+BRGRKaO0ChERERGR\nqGkjx8cftxIAz6VHrFu3DoCBgVB3uOZZ+kEtnqSX1kfOpU5gSZ1jj8/LNvn17NwGwI7NWwCYN39B\nbs7wWCqF9IVNm9anfSueFdIpaiODaduOrWGucjGkPlQL2XUKcSNdJd5nRy59Y8mSxWFM3JC3I94T\nQEtbOIFvYChcZ+mipWnfiSc9B5GpYOHoxsuAdwLHA9uBG4GrxnnOG4C3AWcAbcCTwDeBa919uMH4\nk4ErgAuBxcBO4FbgGnd/uG7s14C3xHt5FfCHwErgp+5+/oG/UhEROdI07eJYRKa1zwHvBZ4BvgyM\nAhcDZwMtwEh+sJldD1wKrAe+C+wCzgE+BlxoZhe5Z7/tmtkrgH8GysC/AY8By4DfAl5lZhe4+70N\n7uvzwIuB7wM3A9UGY0REpIk17eK4tTXZbJZFjqvV8LNzNG7MK5azyLHHDBOL0dpccBhPPrFYMi2X\njfLM+qcA+OsvfgqAWV1dad/W7T0A7OzZGK6f+3lvhfAz97Yf/Wva1rMjRHyTknHV3M9lj1Hh1nKI\nBM+eOyebqxTLtMVod2tbW/Z1iKXfyvE1zO6YnfaVS9k4kcPFzM4lLIwfB85y9x2x/Srgx8BS4Knc\n+EsIC+MbgTe5+2Cu72rgI4Qo9OdjWxfwLWAAeIm7P5gbfwpwN/AV4MwGt3cmcIa7P7kfr+eeMbpO\nnugcIiIyfSjnWEQOt0vj48eThTGAuw8BH2ow/nKgArw1vzCOPkZIyXhTru3NwDzgI/mFcbzG/cDf\nAGeY2bMbXOvT+7MwFhGR5tO0keNqjJTmS54lpdxGYqmzcrGWe0Yux5jswJDQEz+OkdlCrgRctRKi\nwT+763YABnJl1GqlljC+FO6lmLvexo0hMFaoZiHqlpYw3mMZOvPcPcX7OenkUB7OcnXedvWGCHVS\npC3/soaHwv3Nbg05yuV4DYCa51+/yGGTRGx/0qDvDnKpDGbWAZwGbAPel3/f5wwDq3KfvyA+nhYj\ny/VOjI+rgAfr+n423o034u6rG7XHiHKj6LSIiExjTbs4FpFpa2583Fzf4e4VM9uWa+oi/Oa6kJA+\nMRHz4+Mf7mNcoyMiN03wGiIi0qSUViEih1tPfFxc32FmJWBBg7G/cHcb71+D55y2j+d8vcG9eYM2\nERGZQZo2crx4YQcAw0NZhafZc8IGtG3bw19t22vZ7wZJeba0TFvuR2T6Uze2JeXeQlv4uBxLrbUU\nshPoim3hHqrxlL5iIUvxKMcNdj6UbdIbrcYT/OImulou1aMY68IdtSBs+KvmbrBSDafteUy9KM/J\nAmKzZnXu8RpaWrI5S4VRRKbAvYR0g/OAJ+r6XgQUk0/cvc/MHgCeY2bd+RzlcdwN/Dah6sSvJueW\nD8wpR8/lHh2oISJyRFHkWEQOt6/Fx6vMrDtpNLM24JMNxn+WUN7tejObV99pZl1mls/t/Sqh1NtH\nzOysBuMLZnb+gd++iIg0s6aNHF/0orBHxgtZpLQQI7dPPh42w7WUs81p/THCnD/gIzE3lk1b0B3K\noG3bsSvt6+sNUduR0RihLmfl0YrF8OVtbQ1tLaXsd5GtW8KhIV4Zyi5UjiXZLP5n8Wz8UYtCxPj5\nZ5wEwMJFi9K+4ZEQfU42EdZyUWWLMWOrhj7Pv76i/oIsh5+732lm1wHvAe43s++Q1TneSah9nB9/\nvZmtBt4FPG5mtwDrgG5gBfASwoL4HXH8djN7HaH0291mdivwAOFvP8cQNuzNJxwkIiIisoemXRyL\nyLR2OfAIoT7x28lOyLsSuK9+sLtfZmY/ICyAX0oo1baDsEi+FvhG3fhbzexU4I+AlxNSLEaAjcBt\nhINERERE9tK0i+NSjApXPcur3RyjtS3tIWC0bPmxad8jjz4WPoil2Npas6jyb/7mRQCcfFKoALVu\n7VPZ8x4Jz3vsyVAatX8wy3EulJNDOcJcXXOzA0IWd4cN+4ND/Wnbk0+HgNlIzGk+cflRad+rXvri\ncM9Lw14lyx1u0tIaruNJqma+AlyMGJuH/9SlUvaffLS614m7IoeFhz9hfDH+q7d8jOfcBNy0H9dY\nC7x7gmMvAS6Z6NwiItK8lHMsIiIiIhJpcSwiIiIiEjVtWkUhlkrbunln2rZ23ToAym0hrWJO3GgH\nUC6HL0UlplWsWLE87TvrrOcB0N7WDsBRi7PyrM97XtgkvzOeUjc4mJ1uW4lpC63xVLqWXKpGW7yH\nXT0Daduff/GrAKzfFM5G+I2XnJPdw5mnAjAyGu4vv7GuUgkfJyf35U8R81IyrkEfOiFPREREJE+R\nYxERERGRqGkjx7VK2Ij3+BPr0rYtW0IJts45oVTquvVZxaihkbhxz0M09cQTjk/72lrDwR6V0Vh2\nrZD9TuFx/JzZ4cCPrnmz0z6LJdUKMVo7Wsk2BxYszDHYktsUF0urdbSFjXVL5mcb+KpxY12lWt1j\n7vw9tMVDRwq5HXmVShxfLMZbz+69WNTvRiIiIiJ5Wh2JiIiIiERaHIuIiIiIRE2bVpGkQGzasi1t\nG4mb7QoDuwF4end20t3oSOg7etF8AE4/bVXal5xst3swzDk4OpL2lUoh5WJ4OLQlG+0AyuXQV01b\nsnSH0dGQYjHQl23IG4kb6+bOCakZXfPmpn21+NxiTI+oxtcCEDMtGBmu7DEGcmkVtb03342MjOzV\nJiIiIjKTKXIsIiIiIhI1beR4eDhsdHvssew0u2KMANdqlb3GezVEZk9cuRKAo45ekvbVaiH6mmxm\ny29qI26MS6K1e5ZYC9dJyqflI7oen+e1LK6cbNybOydEjFtaytnrGQqvp1oNEefKaPa8cjlEq+Oe\nPYaqQ2lfNYaV416/NJpdfz8iIiIiosixiIiIiEiqaSPHjz7yGAD9A31pW2trKHXWPTsc5rFhy+a0\nzy1EWI8+OuQcu2eR2b7+kBfsMTRrtSw6PDwcDv0oxYM+8kHlZI5CIURoK5V8xDqWdxvJyrsN9oV7\nPXZpNwDlchbZrSW5w8khHpbdw2glRIqrHi5eLmX/WS2WjEsi1bVc7nE+yi0iIiIiihyLiIiIiKS0\nOBYRERERiZo2raK1NWxSm93RmbaNVMLvAqtWrADg9NUXpX0e0w9OOH5pGDvQn/ZVYiZCNZZfy59A\nVyqGL2Gy0S2fqpCkQCRl26rVrK8UUx86ZmXl2k45/VwAznx2PJ1vj9SJUHatEK/XEtM4INtYl2wU\n3CNdIqZyeLyXfPm2/BwiRwozWwvg7sun9k5ERKQZKXIsIiIiIhI1beS4rSW8tLmzskM5OuPHJ590\nEgCnnPO6tC8pmzYysC489j6c9hVjlDfZPFfM7borxYhxEpFNSqdBFh1OIrnJQSFhrvA4p2tx2nbZ\nuz8aPhjcCMCuLT9N+5I53JNydNlrTfboJSXnKnscEBLaWltb4/OzJ1Yr2WZAEZl892/oYfkV35/S\ne1j7qVdN6fVFRI40ihyLiIiIiERNGzkejaHZE09YnjXGHN5Fi0O5tmIpyx32eLhGqRyObt7el+Uc\nd7SFqGtySMdoLm+3FiO6Vgx9+eJoSbQ3yT3OR21HqyG621JrTdvmzF0AQO/QhjB+j5Jxw/F64TF/\nmEeSa5xEjPcsGRf09YUjszs7sxzsocHhvcaJTAcW/k9zGfBO4HhgO3AjcNUY41uB9wNviuMrwH3A\nde7+j2PM/17g7cBxdfPfB8ppFhGZqZp2cSwiR7TPERavzwBfBkaBi4GzgRYg/Q3VzFqAW4DzgIeA\nLwEdwOuAb5vZ6e5+Zd38XyIsvDfG+UeA1wBnAeV4PRERmYG0OBaRacXMziUsjB8HznL3HbH9KuDH\nwFLgqdxTPkhYGP8AeI27V+L4a4CfAR8ys5vc/a7Y/mLCwvgR4Gx33xXbrwT+Aziqbv593e89Y3Sd\nPNE5RERk+mjaxfHChYsA6Jo3P20bGgon3XV3zQOgrTXbrDe8uweAJJOhXMrKnCWb2iwp29aWPa9c\nKsfnhZSJlnK+PFpIp0hOqSuVs7SK4ZGQ0lAstqdtm9avBWDjujXh3rMuqrGeXDnOXyplaRXFclLK\nLTx2ds6h3sjIUByTpZkXWpRyLtPSpfHx48nCGMDdh8zsQ4QFct5bCRlNH0gWxnH8FjP7GPAV4A+A\nu2LXW3Lz78qNH4nz3zGpr0ZERI4oTbs4FpEj1pnx8ScN+u4A0pIwZjYbOAHY4O4PNRh/W3w8I9eW\nfNxoEXw3IV95wtx9daP2GFE+s1GfiIhMX027OG6JkdV8BLgtbqwbGe4F4Jabv5H2lTz8vO2JG/GO\n6i6mfStXhINB+vtC5Lnclosqx1BzZSikQA4Xs01uyaEfrTHSbOXsy93SEtrWr380bfv2jX8JQBLM\nuuSNr0375szqCh/Ukmh07sXGgHR7vE5bWxZyTjYFlkrh9dRyNeB0CIhMU8nJOJvrO9y9YmbbGox9\nZoy5kvZ5E5y/ambb9+NeRUSkyejv6iIy3fTEx8X1HWZWAhY0GLtkjLmW1o0D6B1n/iIwv75dRERm\njqaNHIvIEeteQjrCecATdX0vAtI/67j7bjN7HDjOzFa6+6N14y/IzZn4BSG14kUN5j+HSfy+eMrR\nc7lHh3CIiBxRmnZxvPGZcMrcyEhWkSlJqxiMNYOfWftg2peULm6JY3q2Z+kH82aFFI15cSNfJXey\nXFLDOKlDPDqa9Q0ND8S2MHlrbgNgW3v4uG9gIG1bujjMNX/esjBnb/bX3d5Y17g3pn3kT+mb3z03\nmTTeU+6Uvvi8YjGsJ9pas7rKVtAfDmRa+hphA91VZva9XLWKNuCTDcZfD3wcuNbMfts95EiZ2QLg\nj3NjEn9H2MSXzN8Tx7cAnzgEr0dERI4gTbs4FpEjk7vfaWbXAe8B7jez75DVOd7J3vnFnwFeGfvv\nM7ObCXWOXw8sAj7t7nfk5v+JmX0ZeBvwgJl9N87/akL6xUbSTP6DsnzNmjWsXt1wv56IiOzDmjVr\nAJYf7utasmFLRGS6yJ2Qdxl7nmB3JQ1OsItR5Q8Ab2TPE/K+5O7fajB/AbiccELeirr51wOPu/vp\nB/kahgkpIPcdzDwih1BSi7tRpReR6eA0oOrurfscOYm0OBYRicxsJeFwkBvc/Q0HOdc9MHapN5Gp\npveoTHdT9R5V0qmIzDhmtsSS03mytg7CsdUQosgiIjIDKedYRGai9wFvMLPbCTnMS4ALgWWEY6j/\naepuTUREppIWxyIyE/07IZftZUA3IUf5EeALwOdc+WYiIjOWFsciMuO4+63ArVN9HyIiMv0o51hE\nREREJFK1ChERERGRSJFjEREREZFIi2MRERERkUiLYxERERGRSItjEREREZFIi2MRERERkUiLYxER\nERGRSItjEREREZFIi2MRERERkUiLYxGRCTCzZWZ2vZltNLNhM1trZp8zs679nKc7Pm9tnGdjnHfZ\nobp3mRkm4z1qZrebmY/zr+1QvgZpXmb2OjO7zsz+y8x64/vpGwc416R8Px5LaTImERFpZmZ2PHAX\nsAj4HvAQcBZwOfAKM3uhu2+fwDzz4zwnArcBNwAnA5cCrzKzF7j7E4fmVUgzm6z3aM41Y7RXDupG\nZSb7MHAa0AesJ3zv22+H4L2+Fy2ORUT27S8I34jf6+7XJY1m9lng/cDHgXdMYJ5PEBbGn3X3D+bm\neS/w+XidV0zifcvMMVnvUQDc/erJvkGZ8d5PWBQ/BpwH/PgA55nU93oj5u4H83wRkaYWoxSPAWuB\n4929luubDTwDGLDI3fvHmWcWsAWoAUvdfXeurwA8ARwbr6HosUzYZL1H4/jbgfPc3Q7ZDcuMZ2bn\nExbH33T3392P503ae308yjkWERnfBfHxR/lvxABxgXsn0AGcs495zgHagTvzC+M4Tw24pe56IhM1\nWe/RlJn9jpldYWYfMLNXmlnr5N2uyAGb9Pd6I1oci4iM76T4+MgY/Y/GxxMP0zwi9Q7Fe+sG4JPA\nnwE3A+vM7HUHdnsik+awfB/V4lhEZHxz42PPGP1J+7zDNI9Ivcl8b30PeDWwjPCXjpMJi+R5wLfN\nTDnxMpUOy/dRbcgTERERANz9z+uaHgauNLONwHWEhfIPD/uNiRxGihyLiIwviUTMHaM/ad91mOYR\nqXc43ltfIZRxOz1ufBKZCofl+6gWxyIi43s4Po6Vw7YyPo6VAzfZ84jUO+TvLXcfApKNpJ0HOo/I\nQTos30e1OBYRGV9Si/NlseRaKkbQXggMAHfvY567gUHghfWRtzjvy+quJzJRk/UeHZOZnQR0ERbI\n2w50HpGDdMjf66DFsYjIuNz9ceBHwHLgsrruawhRtL/P19Q0s5PNbI/Tn9y9D/j7OP7qunneHee/\nRTWOZX9N1nvUzFaYWXf9/Ga2EPhq/PQGd9cpeXJImVk5vkePz7cfyHv9gK6vQ0BERMbX4LjS4NZq\nBQAAIABJREFUNcDZhJqbjwDn5o8rNTMHqD9IocHx0T8DVgEXEw4IOTd+8xfZL5PxHjWzS4C/Au4g\nHEqzA3gW8JuEXM7/AS5yd+XFy34zs9cCr42fLgFeTnif/Vds2+bufxTHLgeeBJ5y9+V18+zXe/2A\n7lWLYxGRfTOzY4CPEo53nk84ielG4Bp331k3tuHiOPZ1Ax8h/JBYCmwHfgD8P3dffyhfgzS3g32P\nmtlzgQ8Cq4GjgDmENIoHgH8E/trdRw79K5FmZGZXE773jSVdCI+3OI79E36vH9C9anEsIiIiIhIo\n51hEREREJNLiWEREREQk0uJYRERERCSacYtjM1trZm5m50/1vYiIiIjI9DLjFsciIiIiImPR4lhE\nREREJNLiWEREREQk0uJYRERERCSa0YtjM+s2s8+a2ZNmNmxmG8zsb8xs6TjPucDM/tnMNpnZSHy8\n0cx+Y5znePy33MxWmdnXzexpMxs1s3/JjVtkZtea2f1m1m9mQ3HcXWb2UTM7doz5F5rZJ83s12bW\nF597v5l9PJ7GJSIiIiITMONOyDOztcCxwO8BfxI/HgCKQGscthY4s8Fxm38CXBU/daCHcN58cvzm\np9z9Qw2umXyR30w4t76DcCRnGbjF3V8bF77/TThOFqAK9ALzcvO/093/qm7uFxHOFk8WwSNADWiL\nnz8NXOTuD4/zZRERERERZnbk+DpgJ3Cuu3cCs4CLgV3AcmCPRa6Z/W+yhfEXgUXu3gUsjHMBXGFm\nvzvONf8C+DnwXHefQ1gkfzD2fYSwMH4MeAnQ4u7dQDvwXMJCflPdPR0L/BthYfyXwMo4vjM+50fA\nMcA/m1lxIl8UERERkZlsJkeONwPPcfftdf0fBD4DPOnux8U2Ax4BTgBucPc3NJj3H4A3EKLOx7t7\nLdeXfJGfAE5x98EGz38QWAX8b3f/9gRfyzeANzF2xLqFsBg/FXi9u39nIvOKiIiIzFQzOXL85fqF\ncZTkAK8ws8748emEhTGECG4j18TH5cBZY4z5YqOFcdQbH8fMd84zsw7g9YQUis82GuPuI0CyIL5o\nIvOKiIiIzGSlqb6BKfTzMdo35D6eB/QDZ8bPt7r7A42e5O4Pm9kG4Og4/u4Gw/57nPu5GTgb+FMz\nW0lY1N49zmJ6NdBCyH3+dQhuN9QeH48Z59oiIiIiwsyOHO9u1OjuQ7lPy/FxYXzcwPjW142vt3Wc\n5/4p8K+EBe+7gNuA3lip4v+Y2by68UmE2YDF4/ybE8d17OPeRURERGa8mbw4PhBt+x4yrupYHe4+\n7O4XAy8APk2IPHvu80fM7LTcU5L/dj3ubhP4d/5B3ruIiIhI09PieGKSiO++UhOW1Y3fb+5+t7v/\nX3d/AdBF2OS3jhCN/kpu6Ob4OMfM5h7o9UREREQko8XxxNwbHzvNrOFmOzM7kZBvnB9/UNy9391v\nAN4Wm1bnNgn+D1AhpFW8YjKuJyIiIjLTaXE8Mb8k1B8GuHKMMVfHx7XAz/b3ArHs2liSTXlGyEnG\n3XcD343tHzWz2ePMXTKzWft7TyIiIiIzjRbHE+ChGPSH46cXm9l1ZjYfwMzmm9kXCOkPAB/O1zje\nD/eb2SfM7PnJQtmCs8gOGfl53al9VwA7gBOBu8zsFWZWzj13pZl9AHgIeN4B3JOIiIjIjDKTDwG5\nwN1vH2NM8kVZ4e5rc+3546NrZMdHJ79k7Ov46D3mqxuzK84FYeNeDzCbrGLGNuBCd/9V3fOeT6jN\nfFRsGiXUTJ5NjDJH57v7TxpdW0REREQCRY73g7t/GLgQ+B5hsToL2E4owfbSRgvj/XAx8EngTmBj\nnHsE+BXwKcJpfr+qf5K7/xw4Gfi/wF1AH6E+8wAhL/kLwHlaGIuIiIjs24yLHIuIiIiIjEWRYxER\nERGRSItjEREREZFIi2MRERERkUiLYxERERGRSItjEREREZFIi2MRERERkUiLYxERERGRSItjERER\nEZFIi2MRERERkag01TcgItKMzOxJYA6wdopvRUTkSLUc6HX3FYfzok27OP74FX/hAGZZW62WHJVd\niP+bC5znxgGQO1W7ZGFcqVwGoFgopn3lUjHOFZ5QsPqJsqmsWE7bioUwzqsjaVt1dBiAzs7OMN72\nDuyXiqV43dasrRA/LtTCPLk5k9dVjB+0tLSkXYVCmP9lb71g75sWkYM1p729vXvVqlXdU30jIiJH\nojVr1jA4OHjYr9u0i2MRObzMbDnwJPB1d79kSm9meli7atWq7nvuuWeq70NE5Ii0evVq7r333rWH\n+7pNuzh+9LEHAGjNRUrbOzoA8BBgZXBwOO1rbQ3R17a28Nje3pk9rzU8b3Q4RGSr1WrW19YWnh8j\nwcVC9iUtxehuMUaMPRefLSRB4VzjSGU09Fmcw7K5klFmIVLtuah3xSuhL4aoh2uVtM+tFl9fuIct\n2zekfZs2bQLgZVyAiIiIiDTx4lhEZKrdv6GH5Vd8f6pvQ0RkSqz91Kum+hYOiKpViIiIiIhETRs5\nXvPw/wBQLGab50ql8HI9ph/09w+kfcnmtI72dgBmz5mT9s2eHT4eGhoCYHAoSw6fG8fNmzMrNNTy\nv2+ElI558xYA0BbTOsK4kJrRUsrGDw+F+9k9MhiftzCbKW4G3L51R7iH0f7s3kshdaI2EtJEdm7d\nnPa1d4S0j/LccH8//elP075du3YB8GH+P0QmU8w//hTwUmAWcD9wtbvfVDeuFXg/8CbgeKAC3Adc\n5+7/2GDOJ4GvA58APgZcACwAfsPdbzez44ArgN8AjgYGgQ3AncBV7r69bs43AG8DzgDa4vzfBK51\n92FERGTGadrFsYhMmWOBnwFPAH8PdAO/A3zPzF7q7j8GMLMW4BbgPOAh4EtAB/A64Ntmdrq7X9lg\n/uOBnwKPEBay7UCvmS0Ffk4on3Yz8F3CgncF8HvAF4F0cWxm1wOXAuvj2F3AOYRF94VmdpG7Zwn8\nIiIyIzTt4rhcDj/TWtuyyHFlNERkR0bDxjcrZD/3Rirh44GdITK7e3Br2jdnaNYec1cr2Ya8qu8E\nYGdfCEd7LfuS9veHOavVuJ0uX0Yt7p4rVmtpW0uMclfivcydPz/ta+8IEe2Bnt5wvyND2euKm+56\ntoR7XtyRbSZctngpAE/0hijxxlxU2XPl6kQm0fmEKPE1SYOZ/QPwQ+D/AD+OzR8kLIx/ALwmWYia\n2TWExfWHzOwmd7+rbv4XAZ+sXzib2XsIC/H3ufvn6/o6gVru80sIC+MbgTe5+2Cu72rgI8BlwB7z\nNGJmY5WjOHlfzxURkelHOcciMtmeAv4k3+DutwDrgLNyzW8llAH/QD5C6+5bCNFbgD9oMP9m4JoG\n7Ym9imK6e39+AQxcTkjheGtdO/Ha2wmpHiIiMsM0beS4pRhybcmVXSsW9nys5kqrtcRSZ5RCY6Gc\n/d5QKMQobzyUY1Zre9rn6fzhefkyaqViPOgjHgwyWO1J+zpbQxS5PXegiMec5lo1RLbXbdqV9g0N\nh/THlfNDHvLyWfPSvv4YyR6M1z56XnbmwEmLjgZgS5y7MxdV7u3bjcgh8Et3rzZofxp4AYCZzQZO\nADa4+0MNxt4WH89o0HffGPnA/0rIRf6Smb2ckLJxJ/Cge/Z3EjPrAE4DtgHvswYH9wDDwKpGHfXc\nfXWj9hhRPnMic4iIyPTRtItjEZkyu8Zor5D9tWpufHxmjLFJ+7wGfZsaPcHdnzKzs4CrgVcAvxW7\nnjazz7j7F+LnXYTfZhcS0idERERSSqsQkamQ/BllyRj9S+vG5Y2ZLe/ua9z9d4D5wPMIlSsKwOfN\n7Pfr5vyFu9t4//brFYmISFNo2shxf39IIxgdzTauJafEVWP6Qa2W/eW3VAxpDh1tIWWi3Jp9aZIN\ncqOVcEJerZg7gS5uqKvEvT79A9n1vBDmbIlpGG2VbPNdR5x+wZxss1/LrPC7ykBMoegc6kv72tpD\nmsiyOJf3ZKXcRuI15xTCiXxz58xN+95w6VsAmPWzOwD4u+98O+0rFLUjT6aGu+82s8eB48xspbs/\nWjckObbx3gOcvwLcA9xjZncB/wm8Fvhbd+8zsweA55hZt7vvOMCXsU+nHD2Xe47QIvgiIjOVIsci\nMlWuJ6Q3XGvJueiAmS0A/jg3ZkLMbLWZzW3QtTg+DuTaPksoRH69me2VumFmXWamfGERkRmoaSPH\n1VqIvo5WRrPGuPHG44a3UjnbDEctRFEH+0JEtlppTbvKcdzocIgY9w1lUdvWeDiHlYrxErlDPWK5\ntUo1PC8p3wbgMWpbyALNLOoIUeTOOMWq5cvTvrYYAd+5YQsAT2zKgl1P9MUIc0u4h5+u+XXad9u9\ndwPwspeeD8Att/0g7auO5tcKIofdZ4BXAhcD95nZzYQ6x68HFgGfdvc79mO+3wPebmZ3AI8DOwk1\nkV9N2GD3uWSgu19vZquBdwGPm1lSTaObUBf5JcBXgXcc1CsUEZEjTtMujkVkenP3ETO7CPgA8Ebg\nPWQn5L3P3b+1n1N+C2gFzgVWEw4H2QDcAPyZu99fd/3LzOwHhAXwSwmb/3YQFsnXAt84wJcmIiJH\nsKZdHM+eHSK67iNpWzGWZBsdDbm/Q/1ZNSgvhKjy0EgY39efRYfb47HPpRh5rlayCHB/jA4PjYbn\nlVrKaV8plmur1kKkulDODgHpHQjzt+X+C8yLx1Qv6u4CYHFrW9o33B8ixSNxip7hLB95KFbNavUQ\nOR4eyMq2fueGGwA44zknAnDhC85J+355332ITBZ3X0tS07Bx//kN2oYI5dc+MQnz/5Rwct6ExeOs\nb9rnQBERmTGUcywiIiIiEmlxLCIiIiISNW9aRVc4CW64mqVOzOoMG95GhkKaQ8+O7KyC4eHQNjQY\nNqkVW7MUiNFKmMOTzXa5EnC1WMrNLZZpy5VHK7eE8W3tIS2jWM1KwB0dUyZesvLEtO05i4+Jc4TU\njJ5t2fkIO3p6AegdiSkhubm6YirH4Mhw7MtSSXZu2wzA9/7pewC89rWvTvtWdM1HRERERDKKHIuI\niIiIRE0bOW4rhJc2p709betsD+XZhmNJtVlLF6R9pUKIvm7bvhPIIsIAsztDFLpcipv8allfS4ww\nj/po/DwrAWdxA19LLPc22p9Fqs+JZdrOXXFC2lashd9VeuKmwJ292fhn+kNEe+dQuHZbbnPf3Lmh\nTGtpbogEr9+dHSq27Zlw0u7N//ETAM5/0Xlp34nHLEdEREREMooci4iIiIhETRs5ftbcEBUudC9O\n20rF8HILMT+46lnucP9QiNa2xohxcTiLDj97xUoAdg+F6O32niyiO39BiNbO6QgR6tZc5Ng9RKh3\n7Qrj+3Nzto2GqHKhlEWAi/EI66Gt2wEYHM3yip8eDuXZereFEm5z2menfac+53QAXnjRawB4cH2W\nq/zUo+FU3v++N5yl8MNbb037fvvlFyEiIiIiGUWORUREREQiLY5FRERERKKmTatY9azjAKjlNs+V\n48a4aiWkUKx54tG07+GHHwagd2vYzLZyybK0r9oXTrPbuv5pAAbiqXgAS2aF9IaF87oBKBWKad/Q\ncCit1tYeSsjtHMjKym3YEDbKnXTciuz+Yhm4WjwDrGcou86GrSE1Y05L2BxYasn+0518Ykj7SDYc\nds2dlfYtO+f54R46QgrJ048+lvbdf384Tfd0RERERAQUORYRERERSTVt5LjF997w1lIOkdVfPxyi\np/f84tdp36a4ya6rJURduxcsTPs2924DsgNFVhz7rLSvrRS+hBvWrQsNlt3D4MBAvIcwZrSWHRBS\njRHtB598Mm1bsTTMO1wI43buzEqyzS6EDX+DwyHqXSpmF9q1YysAI4+E1/PIpg1p35K5c8PrKYXx\ni09amfYV9auRiIiIyB60PBIRERERiZo2cnzis5YDUChkL3FbbziCec3jTwCwtb8v7RuJgdjk2OiR\nWlZGrX80RIznzA95xaO5EnCPPhGi0LPawnHQNc9ynIdHQ5R3eCQcEDIwnB3r3NIa85/JxruFfOW5\ns8Jx0+ecekbWVwv5wU9sDmXazlz13LTv6Pkhyj27qwuAxfPmpX1dMXI8EPOmi4Xs9yEr5MLcIiIi\nIqLIsYhML2a21szWTvV9iIjIzKTFsYiIiIhI1LRpFY/vXA9AW0tH2vZE3DT3xObQN1QdTfsKpZDS\nUPOQTvHkurVpX1tH2MjX1h7mWvNYVg5tNJZb6+oMG/kqtSzlomZhY91wJcy5vXd32tcRT9Kr5krN\n9ewKG/Cec8IJABy/OCsnN3t2uPbS0lIALviNF6d9Ry8OaRTJZr3ZhXLaV24N97OzN2w4HB7MyslV\nKlnqiIiIiIgociwiIiIikmrayPET68Kmu9Zia9r22JNrAegfDJvTyB3Y0V4M0dZiMbT1Dg2mfYOE\nCOvuGCXu7+9P+1ri+N0jISLbEjfmQbYhbyBGaHfnNvkNDO4dtR2OJd8eeSLcZ7GWO1AkRrk3bgll\n2u755S/Svrazw0EfuwfCfdVy++zmL1gQnp+WgMv+k5fKWZk7kcPJzAy4DHgncDywHbgRuGqc57wB\neBtwBtAGPAl8E7jW3YcbjD8ZuAK4EFgM7ARuBa5x94frxn4NeEu8l1cBfwisBH7q7ucf+CsVEZEj\nTdMujkVkWvsc8F7gGeDLwChwMXA20AKM5Aeb2fXApcB64LvALuAc4GPAhWZ2kbtXcuNfAfwzUAb+\nDXgMWAb8FvAqM7vA3e9tcF+fB14MfB+4Gag2GLMHM7tnjK6T9/VcERGZfpp2cbyscz4ApXIWyX1s\nOBy4UYl5vpaLohbjoSEtMZqaD0Nt6Qm5wPFsjj2OiC7E8QPV8DN0eCR7ZpXwhKF4vUp2BggVD5+M\n5Mqp9VRCdLhvezh0pC0eTQ2wezCUnVu1MuQjv/D556Z9xx51fLh2ZTjOneVSd84OudBHz18eW1S+\nTaaWmZ1LWBg/Dpzl7jti+1XAj4GlwFO58ZcQFsY3Am9y98Fc39XARwhR6M/Hti7gW8AA8BJ3fzA3\n/hTgbuArwJkNbu9M4Ax3f7JBn4iIzADKORaRw+3S+PjxZGEM4O5DwIcajL8cqABvzS+Mo48RUjLe\nlGt7MzAP+Eh+YRyvcT/wN8AZZvbsBtf69P4ujN19daN/wEP7M4+IiEwPTRs5FpFpK4nY/qRB3x3k\nUhnMrAM4DdgGvC+kKu9lGFiV+/wF8fG0GFmud2J8XAU8WNf3s/FuXEREml/TLo5PO+k0AHbnypXt\n+s87APCYTpE/Ia4WUx9qMZZeK2WpE0nKRNJSzpVfI/6wLlt4ouX6ajGtIjkhD7fc08L4YXK5FjFl\ncnQ4PD6+eVOuKwTMzn3R2QCsPv20tK+lFDYdFspxzko+uBbmb7N2ACrVXKm5/OsQOXzmxsfN9R3u\nXjGzbbmmLkIu0EJC+sREzI+Pf7iPcbMatG1q0CYiIjOI0ipE5HDriY+L6zvMrAQsaDD2F+5u4/1r\n8JzT9vGcrze4N2/QJiIiM0jTRo5b28JGuWc27UrbdveEUmeFGLWt5n4ODsao7dPbQjBrqJpFnEfi\nwR6zyqHcW/ecbKPccH+I0vZXwub62kguclwL81fj86u5Um61+LO81peN7+4I87e1hYBWz0BWMm7V\nSccCsKuvF4Cbbr057euMh5SU4/3VPJtzwfywzijHUnXDQ9mGwY6OcLDIKbwEkcPoXkJqxXnAE3V9\nLyL7Iw3u3mdmDwDPMbPufI7yOO4GfptQdeJXk3PLIiIyUyhyLCKH29fi41Vm1p00mlkb8MkG4z9L\nKO92vZnNq+80sy4zy1ee+Cqh1NtHzOysBuMLZnb+gd++iIg0s6aNHIvI9OTud5rZdcB7gPvN7Dtk\ndY53Emof58dfb2argXcBj5vZLcA6oBtYAbyEsCB+Rxy/3cxeRyj9dreZ3Qo8QEiZOIawYW8+4SAR\nERGRPTTt4viXjzwAwONPb0zb+oYHACjFk+jw3Oa0uFEt2aTmlaxW8FELw/6eU048CYD5szrTvmJM\nYegbCnPv7utL+0ZG4jkGsaZxPpmxpy+kN6zfkO3/mTVrDgCFQkiBqFazcxBOPSVUnepsCekivf09\nad9IJbyelthXLGR/ENi2azsAg3FjYs2zu/D48Sn73LckMukuBx4h1Cd+O9kJeVcC99UPdvfLzOwH\nhAXwSwml2nYQFsnXAt+oG3+rmZ0K/BHwckKKxQiwEbiNcJCIiIjIXpp2cSwi05eH38y+GP/VWz7G\nc24CbtqPa6wF3j3BsZcAl0x0bhERaV5Nuzje2LMFgG27c/t3QkCWQjGWXRvNIscd7aHUmcU07N0x\n4gqwcskSAJ57/AoA2opZZLZcDBvrqh4iwdVcqbRCjOC2tcZSa5Y975ltIcL8bz+8LW3r6Q3R51os\n83rqycelfUd3hepXhRh/ttxcye20xusUcyf4tcbOjpFqvIe9y9eJiIiISKANeSIiIiIiUdNGjque\nREqztnKM5BZixLSlmL38JQtDydVNm0Mpt67O7HyAlUcdBUBnnKxkWd5u8nEplkqjVM7uIV6nrRgi\nubNiyTWAaiz5lv/tpKdvKE4R+p5zXBY5Pi6WZEvzpHP3nsyRnB6W5B6H+yrF1xz6WnN94WwFERER\nEUkociwiIiIiEmlxLCIiIiISNW1ahSWn0XlWki3JRBiNm+Y6WrMUiHLcwzYaS7Kd8eyVad+Jz1oW\nxsS0DM+dntce0xTa4lyVSrYhrxjTKdrbQzpFZ2v25d65KzupLtEST/Xrbg/PO3n5MWnf7M5QkrUS\ny8O1t2dpH23xHiqj4bXmN9qVklPz4u9BhVyZN3edlCsiIiKSp8ixiIiIiEjUtJHj9njQR0spi44W\nC+HjpJzZCcuWpn2ds2cDsKU1RGFPPen4tG/hvNBHNURkS7nfKZLDQzpbQmS3VsqitsVSjBy3hr6O\ntmwznFdDqblcRTYWLwqHjRw7twOAWbnxPSP94d49PGGkPztspC90UYqbAWu1LHo93NsbHmM02Qr5\nEnDh42WIiIiICChyLCIiIiKSatrIcakSIqWzi1n5tFnxWOaj5nYBcOpxWV5x/3DI1x05JpRPW9y9\nKO1LjoEuJ2XaStkhG6PV8LxqchhI7h6qxJJxpdDXV8mOg96xayewZ95z15wQMa7EyG/fcDa+ZiHP\n2WJJtupoFqFODhdpjVHvYq7MW99gyKHuibnUeUlO9PP36hERERGZmRQ5FhERERGJtDgWEREREYma\nNq1idks7ALsLu9O2BV3dAJx6yvLweUeW0tDWGtIUyi2hRFqtkm3k2z0c5mhpDxvr8gXQPH42Ohge\nk1QFgOpISI/oj+kUnntmT9xQt6S7K21buCRsyNu5OWzWGxzNSsYNjoTSbxazKQqF7N5HYmm50V0h\nxaOUu4dSSxg3XAt9wyNZqsbw8N7l5ERERERmMkWOReSIYmZrzWztVN+HiIg0p6aNHJfi5rRKrqzZ\nggULAFh18kkA7N78dNo36CEkW6iEqOto7jCPthiJTTbmecHSvmqMBg/sHgSgtTXbAJgcxpFEjIvl\nXLQ3RpOPXrokbSu3hHkH4r335zbkFSweZlKN5eiy4DAj8d5rMTDdn4sI1wbDfbW3hzmruQNCajUd\nAiIiIiKSp8ixiIiIiEjUtJHjnpGQh1to60zb5pVCzvDs1lAybXMliwDviiXPisWQczw8kjssoxSi\nyLV4aMZoLhpdicXbah6itV7NIrPJuBEPj04W7u3pC9ebt3Bh2lbbvQuA7liKrZiby2LJNye8ruHh\nwbRvJDcOoFTK/rNajHIPDg0BuXJ0QKnYtP/5RURERA6IIsciMu1Y8G4ze8DMhsxsg5l90czmjjG+\n1cyuMLNfm9mAmfWa2X+Z2f8aZ/7LzezB+vmV0ywiMrMpdCgi09HngPcCzwBfBkaBi4GzgRYgTcg3\nsxbgFuA84CHgS0AH8Drg22Z2urtfWTf/l4B3Ahvj/CPAa4CzgHK8noiIzEBNuzh+ZkdIUdi+szdt\nW37UPADaOsLj7Xffm/ZtHwzl2s4442wANu/qSfvWr38cgErc+JY8ApTj5rmCh81tLYXsSzpciafu\nFeJpfYVsA1ypL/xs37kzO7nOa+HjRZ0hOHbvr+5P+zrmzwZg4YJQjq6FLCUkSeUoxLQPr2ZpH8V4\nml813t/waPYzv6ANeTINmdm5hIXx48BZ7r4jtl8F/BhYCjyVe8oHCQvjHwCvcfdKHH8N8DPgQ2Z2\nk7vfFdtfTFgYPwKc7e67YvuVwH8AR9XNv6/7vWeMrpMnOoeIiEwfSqsQkenm0vj48WRhDODuQ8CH\nGox/K6H8+AeShXEcvwX4WPz0D3Lj35Kbf1du/MgY84uIyAzStJHjXz34IAAbt+5M20aq4eWetjpE\ne3cNDKV9z2zbCkD31mcA6OrONso9vGEzkJVmK+Y2shWLIYLbUg4R2lIuoptEaYfiJro2z6K2zz/q\nhDAmt7lvdFbYLNcSy7v1bM/uvToQNvyNbNkGwII5c9K+RXNDpLkaI8aVSnZ4SHKYyUg1XLslvyGv\n3LT/+eXIdmZ8/EmDvjuA9P80ZjYbOAHY4O4PNRh/W3w8I9eWfHxHg/F3A5UG7WNy99WN2mNE+cxG\nfSIiMn0pciwi002y6W5zfUeMDG9rMPaZMeZK2udNcP4qsH3CdyoiIk2naUOHXfNCju7u4Sxau2lr\niA6PxDOYTz31uWnfwo2hhNvQQMhR3jnQn/ad+qyjAJjdEcrCdbS2p321GA1u6wy/Z3S2taV9ffEA\njmd2hZ+16zZuSfu6jwlzFuPhHABbejYBsHlTjF7PzqLDJyw7JlwvCWp5li9cjCeCjI7uHfBKhtXi\nB/lDQKgrAScyTSQJ/4uBJ/IdZlYCFgDr68YuobGldeMAko0IjeYvAvOBDft91yIi0hQUORaR6SbZ\nKXteg74XQVYw3N13EzbuHW1mKxuMv6BuToBf5Oaqdw5NHDQQEZF90+JYRKabr8XHq8zxhrAGAAAg\nAElEQVSsO2k0szbgkw3GXw8YcG2M/CbjFwB/nBuT+Lvc/HNz41uATxz03YuIyBGtaSMkpz47bHg7\natlw2vboo+sA+Kd/+iYAC2Z3pH1nnrACgDTRoJhtrOtoD1+mlmL4udtSyE66G+gP6RfVlvB7Rmsp\nS5NITqdbTkih6O5an/Y9tO7h0HfiCdk9H39cmIOQAtHWks1VjpvsiuXQNlDNUiiGK6EsXFt7KwCF\n/KbAkfD6Cy0hFcRyfbVRlXKV6cfd7zSz64D3APeb2XfI6hzvZO/84s8Ar4z995nZzYQ6x68HFgGf\ndvc7cvP/xMy+DLwNeMDMvhvnfzUh/WIjuW8FIiIyszTt4lhEjmiXE+oQXwa8nbBJ7kbgSuC+/EB3\nHzGzi4APAG8kLKorcdz73P1bDeZ/J+HAkLcD76ibfz0hVeNgLV+zZg2rVzcsZiEiIvuwZs0agOWH\n+7rmroMgREQAYt7yI8AN7v6Gg5xrmJAffd++xoocIslBNI3KHIocDgf7HlwO9Lr7ism5nYlR5FhE\nZhwzWwJscc+OuzSzDsKx1RCiyAfrfhi7DrLIoZac3qj3oEyVI/U9qMWxiMxE7wPeYGa3E3KYlwAX\nAssIx1D/09TdmoiITCUtjkVkJvp34DTgZUA3IUf5EeALwOdc+WYiIjOWFsciMuO4+63ArVN9HyIi\nMv2ozrGIiIiISKTFsYiIiIhIpFJuIiIiIiKRIsciIiIiIpEWxyIiIiIikRbHIiIiIiKRFsciIiIi\nIpEWxyIiIiIikRbHIiIiIiKRFsciIiIiIpEWxyIiIiIikRbHIiITYGbLzOx6M9toZsNmttbMPmdm\nXfs5T3d83to4z8Y477JDde/SHCbjPWhmt5uZj/Ov7VC+BjmymdnrzOw6M/svM+uN75lvHOBck/I9\n9VAoTfUNiIhMd2Z2PHAXsAj4HvAQcBZwOfAKM3uhu2+fwDzz4zwnArcBNwAnA5cCrzKzF7j7E4fm\nVciRbLLegznXjNFeOagblWb3YeA0oA9YT/j+td8Owft5UmlxLCKyb39B+Cb+Xne/Lmk0s88C7wc+\nDrxjAvN8grAw/qy7fzA3z3uBz8frvGIS71uax2S9BwFw96sn+wZlRng/YVH8GHAe8OMDnGdS38+T\nzdx9qq4tIjLtxQjHY8Ba4Hh3r+X6ZgPPAAYscvf+ceaZBWwBasBSd9+d6ysATwDHxmsoeiypyXoP\nxvG3A+e5ux2yG5YZwczOJyyOv+nuv7sfz5u09/OhopxjEZHxXRAff5T/Jg4QF7h3Ah3AOfuY5xyg\nHbgzvzCO89SAW+quJ5KYrPdgysx+x8yuMLMPmNkrzax18m5XZFyT/n6ebFoci4iM76T4+MgY/Y/G\nxxMP0zwy8xyK984NwCeBPwNuBtaZ2esO7PZE9su0/16oxbGIyPjmxseeMfqT9nmHaR6ZeSbzvfM9\n4NXAMsJfMk4mLJLnAd82M+W8y6E27b8XakOeiIjIDOHuf17X9DBwpZltBK4jLJR/eNhvTGQaUeRY\nRGR8SRRj7hj9SfuuwzSPzDyH473zFUIZt9PjpiiRQ2Xafy/U4lhEZHwPx8ex8t9Wxsex8ucmex6Z\neQ75e8fdh4Bko2jngc4jMgHT/nuhFsciIuNL6ni+LJZcS8UI2wuBAeDufcxzNzAIvLA+MhfnfVnd\n9UQSk/UeHJOZnQR0ERbI2w50HpEJOOTv54OlxbGIyDjc/XHgR8By4LK67msIUba/z9fjNLOTzWyP\nk6PcvQ/4+zj+6rp53h3nv0U1jqXeZL0HzWyFmXXXz29mC4Gvxk9vcHedkicHzczK8X14fL79QN7P\nh5sOARER2YcGR52uAc4m1Ot8BDg3f9SpmTlA/UELDY6P/hmwCriYcEDIufEHh8geJuM9aGaXAH8F\n3EE4dGYH8CzgNwl5nv8DXOTuynuXhszstcBr46dLgJcT3kv/Fdu2ufsfxbHLgSeBp9x9ed08+/V+\nPty0OBYRmQAzOwb4KOF45/mEU5xuBK5x9511YxsujmNfN/ARwg+YpcB24AfA/3P39YfyNciR7WDf\ng2b2XOCDwGrgKGAOIY3iAeAfgb9295FD/0rkSGVmVxO+f40lXQiPtziO/RN+Px9uWhyLiIiIiETK\nORYRERERibQ4FhERERGJtDg+ApnZcjPzJKdMRERERCbHjD4+Ou7cXQ78i7v/cmrvRkRERESm2oxe\nHAOXAOcBawEtjkVERERmOKVViIiIiIhEWhyLiIiIiEQzcnFsZpfEzWznxaavJhvc4r+1+XFmdnv8\n/E1m9hMz2x7bXxvbvxY/v3qca94ex1wyRn/ZzN5mZrea2VYzGzazp8zsR7G9cz9e32lmtjle7xtm\nNtPTZ0REREQmZKYumgaBzUA3UAZ6Y1tia/0TzOwLwHuAGtATHyeFmR0N3AScHptqwC7C0YzPAi4i\nHKd4+wTmOhf4PjAP+EvgMtdJLyIiIiITMiMjx+7+bXdfQjjXG+Byd1+S+/f8uqesBt5NODJxvrt3\nA1255x8wM2sF/o2wMN4GvAWY4+7zgY547c+x5+J9rLleBvw7YWH8p+7+Li2MRURERCZupkaO99cs\n4JPu/tGkwd17CRHng/X7wBnAMHChu/8qd40qcG/8Ny4z+y3gW0AL8CF3/9Qk3JuIiIjIjKLF8cRU\ngc8eornfHB+/ml8Y7w8zuxT4G8JfAt7l7n85WTcnIiIiMpPMyLSKA/CYu2+b7EnNrExImwC4+QDn\neB/wt4ADb9bCWEREROT/b+/O4+O6yvuPf56Z0S5bsmTLduLYzo5pkgaSBkLSxmxJgNLSFAq0UEKX\nV1PKL5TSXwm/hiYsBbpBW9pAoaX5NQ0NFEqBUkhoIHFWQhwbiONsXrI4jndJ1q6ZOf3jOXPvtTxa\nLEteRt/36+XXle6599wz8rykR4+ec870KXM8NQdN0JshHaT/B09Ps49PxeOHQwj/evhDEhEREZm7\nlDmemtLRHsAEbonHPzSzC47qSERERESOcwqOZ0YxHhsnuKatyrm9mXtXTPPZbwf+A5gP3GpmL5pm\nPyIiIiJz3lwPjitrFdth9tMdj8uqNcYNPFaNPR9CGAXWxk9fO50HhxCKwFvw5eDage+a2dnT6UtE\nRERkrpvrwXFlKbb2w+znJ/F4qZlVyx6/F2gY595/iccrzeyc6Tw8BtlvAr4DdAL/Y2YHBeMiIiIi\nMrG5HhxviMcrzKxa2cNUfRPfpGMR8C9m1gVgZm1m9sfA9fiuetX8E7AeD55vN7O3m1lzvD9vZueb\n2efN7CUTDSCEMAz8EnA70BX7Ov0wXpOIiIjInDPXg+ObgBHgYmC3mW0zs61mdvehdBJC2AtcEz99\nE7DDzPbhNcUfBT6MB8DV7h0GfgF4GFiIZ5J7zWw3MAD8EPgtoGkK4xiKfd0JLAW+Z2YnH8prERER\nEZnL5nRwHEJ4FHg1Xo7QAyzBJ8ZVrR2epK+/Bd4M3I8HtTngHuCXsjvrjXPvM8D5wNXA3cB+fFe+\n7cCteHD8wBTHMQD8fHz2MuD7Zrb8UF+PiIiIyFxkIYSjPQYRERERkWPCnM4ci4iIiIhkKTgWERER\nEYkUHIuIiIiIRAqORUREREQiBcciIiIiIpGCYxERERGRSMGxiIiIiEik4FhEREREJFJwLCIiIiIS\nKTgWEREREYkKR3sAIiK1yMy2APOBrUd5KCIix6uVQG8I4eQj+dCaDY6f2t0TAEZGR5Nz5VIJgFKI\nn4f0+hA/NjM/hrSxED8uFPzLlcunCffK9QU/kMsd3AYhfn5wWy65Bix3YCI/R9pW6Xdsn3Gw8Zr0\n+vR1hYPOVdTV1QHQVFflRhE5XPObmpo6Vq1a1XG0ByIicjzauHEjg4ODR/y5NRscj5IHYKRcSs6V\nY6BYDh4LljPBZ6gEsFSC1jSozOXLfn0aASdthbw/pxDPFQ4IjisBbeXzTCBsE8Sj8dHZwDmXG78C\nJpeLwXHer58gHj4gWC4UVFUjc5OZrQS2AP8/hHDlLD1m66pVqzrWrl07S92LiNS28847j4ceemjr\nkX6uoiMRmRVmttLMgpndeLTHIiIiMlU1mzkWETnaHt7Ww8prvnW0hyEiclRs/cTrjvYQpqVmg+Oi\nV0IcUDpROVcs+wchkzivlBtUKhnq8pmShoKXTtTVN/jnmRKHfKw/roslFNlU/ESlEBXVyisqZ3IH\n1CiPvS/zcSwZTss3Dn5O1VILVRqLiIiIHEBlFSIy48zserymF+Adsbyi8u9KM1sdP77ezC4ws2+Z\n2d54bmXsI5jZHeP0f2P22jFtF5jZl8xsm5kNm9l2M7vNzH5lCuPOmdnfxL7/w8yapvcVEBGR41XN\nZo4b6/ylWUgn5NXlfHWG0bhqRTGzXIXF3xMqWdj6mC0GaGrwvurr64ExmeP4cV2ln4lmw2VVVsfI\n/HqSrJQRj/kpZoCnkKCuSoljmUV3AO3Ae4AfAf+ZaVsf2wAuBD4A3A18AVgIjEz3oWb228BngBLw\nDeAJoAs4H3gX8OUJ7m0EbgauAP4euDqEUJ7CM8ebcfeCQxq8iIgcE2o2OBaRoyeEcIeZbcWD4/Uh\nhOuz7Wa2On54KXBVCOEfDveZZvZC4AagF/jZEMKGMe3LJri3Aw+mXwZcE0L4s8Mdj4iIHJ9qNjhu\na/Es71A+kx2OGdliyZNBo6U0KZSPS7Ilx0zhbkM8l6w1nHlOUuebrGWcWR5uoiRyleXdppsBTpY8\nniAVXK0OWZljOQasn4nAOPpd/HvaR8YGxgAhhGer3WRmK4DvAKcCbw8h3HwoDw0hnDdOv2uBFx9K\nXyIicvTVbHAsIseFB2awr5fG47cP4Z4zgfuAFuA1IYTbZ3A8IiJyHNKEPBE5mp6fwb4qdczbDuGe\nM4ClwGbgoRkci4iIHKdqNnPcWF9ZWq0+OVdZrq1S7lDKTMgbDb7N9FBpAICRkeGkrX9/LwDDQz5P\nqGthV9I2v3U+APU5f45lihWSkovKczNTeyqT7Uq5dAyVZecKcQ5h2bIlIeUDzpUzM/kqS77VVeYe\nZso5RmNZiVV20QsqppBjykTFR4Hxv0e1VznXHY8nAo9O8fnfBB4DPgbcbmavDiHsmeK9IiJSg2o2\nOBaRo67y61p+wqvGtw84aexJM8sD51a5/n58VYrXMPXgmBDCx81sEPgUcIeZvSqEsGN6Qz7QWSe2\nsfY4XQRfRGSuqtngOJ0Ml83kxgl1lUxuPk3lbnj0EQDWPrYOgH39+5K2np69ABTMs8OrTl+VtC3u\nXALAiZ0+EX5J5+KkbV5LCwB1OY8NyqU0SVaIYyjmism5UhxrvnjgsnIAca8RKonmkqVjLxfiyXK8\nr5yZFJjzjHiIGWMLNftfLseefXj2d/k0738AuNzMLg0h3JY5fy2wosr1nwGuAj5oZreGEB7JNprZ\nsvEm5YUQ/trMhvDVLu40s1eEEJ6b5rhFROQ4pkhJRGZFCKHPzH4A/KyZ3Qw8Trr+8FT8JXAZ8HUz\n+xKwF19q7WR8HeXVY573iJm9C/gssM7Mvo6vc9wJ/Ay+xNvLJxjvZ2OA/E/AmhggPz3FsYqISI3Q\nhDwRmU1vB74FXA5cB3yEKS5vFleOeAOwAXgL8A5gK3AB8NQ493weuBj4Lzx4/r/ALwC78I09Jnvm\njcDb8Mz0GjM7ZSpjFRGR2lGzmeNK0UHIruZrlXOxpCGze97Dm7xE8bs/WAPAcHkoaauLE/eWn+B/\nyR0cTSfrbXhiIwA/2eB/wV229MSkbcUyL5dcfqKXXHQ0pXOI9j7lf91tW9SanJvf2QlALs7kG8pM\nVQqxZCIfqzDqMwsXl/M+nlKyq1/6O09DnAUYYjlFOXOfpubJbAshPAm8fpzmSd+CIYRvUD3TfGX8\nV+2e+4BfnqTfreM9P4Twb8C/TTY2ERGpTcoci4iIiIhENZs5ruSEs8uhVdZWi0lY9sYl2gD6SzEb\nHHfWq8ssldYaJ9s3tDT55wvSDHCuzq/v2e8T+HpDT9L20OM7AdiyYxMA56/8qaRtw1e+CUBjeTA5\n9+KLLwSgbdEiH8OSBUlbucWzyqP1Poby6GjS1ljy1zVS8GPIjL0l1Pk4g58LuezKWcodi4iIiGQp\ncywiIiIiEtVs5riyv0c5ZDbSiMehkm/msaN3d9I2HPxcMbaFXLpU2kDRC317BvoOOEK60UcpLgtX\naKlL2kp4dncgbiyye3e6cVfP416j/OCttybndnzvewCcc84LAWhua0raikt8Nay2U071vjP/c0tO\nPweAlsVL/drM8nDluPxcubLXQiZZPNHuCyIiIiJzkTLHIiIiIiKRgmMRERERkahmyypKlR3oyml5\nRCHvE+ue37cLgO6h/UlbiMu65WMJBYW0/qAYPxwqedsz29ONs5oaGgEYGPLJfXUN6Ze0EHela272\nnfJ2DqRlHHv3eYlF+/50Al/xMS+12Dvi4xpsmZ+0PTP8IwB648TB+fPT8o3TLnkVAKefdTYAC09O\nl2YNi7zUItfeAUA5s3seeU3IExEREclS5lhEREREJKrZzHE5ZoxLmY0+9u3rBuC5Pb7EWmhMM6eN\nDQ0ALGjwSXDD5XSjj9HY1jLPM8CDIwNJ28iIT+Cry3lfPXvS5eHqcp6pLg77WPJL2pK23NJ5/py6\ndHzlkm880h2Twl2XpTvdLhvyMTz38MP+unZvTcfwtG9EsuHH9wPQ0JYuNdd1+eUAnPn6N/nYy/VJ\nW2WVOyWQRURERJwyxyIiIiIiUc1mjgtxLbd9Q/uSc5v3eK1wKS51ls/U39abZ3kXxcyxZWqOC61e\n+9u6yDO/xUIm2xszup34fUXSZdSGi76UW7EYs8v5xqSt9Wd+GoAntzyZnFt+6vkANC7wOuHB085M\n2i565S8A8NQPfgjArqc3JG2nnODX99z3AADr1nw3aese9mXnFtb5s8unn5W0tZzky8I1NKbZZBER\nEZG5TJljEREREZFIwbGIiIiISFSzZRXb9/hSaesfvT851z3UD4ANxHKHvsGkbbTfyw+ae3wZtfb5\n+bSzfi+L6Bl6FoDefLpDXsfiVQC0xF8zegfSyXrEpd/ycfe83u69SVNvs/fffPE5ybmTV3vpRMNo\nnHzXvT1pG270B4x0+US+nj3p7zXDTzzlj1v3KAAn9Qylr+s+XwJuz0Zfvq7lFauTtr0/eyEAqy5/\nPSLHGjMLwJ0hhNVTvH418H3gQyGE6zPn7wAuCSFo6qmIiExKmWORGmFmIQaCIiIiMk01mzl+dON6\nANZ85xvJuTDqGd8FZc/MDu5Js7yDw750W2ucrNfYlW7AMTjiG3XsHfTJfUPNI0lbXSFurrHAv5Td\nu9INQnr7PVPd2NIMwK7nn03ahkpxo49yf3JuzeM/AKC9yZdia8ksQ7f1sbXe/6AvFbe9N33O4AMP\n+uvb4puIFMNo0lYu+cTE0cd+DEBzfZpV3tC3GVDmWGrGA8AqYPdkF4qIiIxHmWMRqQkhhIEQwqMh\nhGMmOH54Ww8rr/nW0R6GiIgcAgXHIkeImV1pZl81s81mNmhmvWZ2j5m9rcq1W81s6zj9XB9LKFZn\n+o1bunBJbKv8u37Mvb9iZmvMrCeO4Sdm9gEzaxhvDGbWamafMrNn4j3rzewN8ZqCmf2xmT1hZkNm\ntsnM3j3OuHNmdpWZ/dDM+sysP378u2Y27vciMzvBzG4ys53x+WvN7FerXLe62mueiJldZmb/bWa7\nzWw4jv8vzKx98rtFRKQW1WxZxYY71wBge7qTc7n9nlBqrPdJbaEvJG17nt8BQGfXAgCaBtK2eXVe\nFlHf7msZ7x7MlEfENYxD3ksgysV0kp8VvYShPOBtDXWZ+COugdyzPy3tePKpxwFob/ad+Np3pbvt\n7b3fd8brjWMYCOl9rZ0+ua/91WcDMFJI44ww5G27H/SSi1xvOslvy1bkyPoMsAFYA2wHOoHXAjeZ\n2ZkhhA9Os9/1wIeA64CngBszbXdUPjCzjwEfwMsOvgj0Aa8BPgZcZmaXhhBGOFAd8F2gA/g6UA+8\nFfiqmV0KvAt4CfBtYBh4E/BpM9sVQvjSmL5uAn4VeAb4RyAAvwTcAFwM/FqV17YAuBfoBv4ZaAd+\nBbjZzE4MIfzFpF+dcZjZdcD1wF7gv4CdwDnAHwKvNbMLQwi94/cgIiK1qGaDY5Fj0FkhhE3ZE2ZW\njweW15jZZ0MI2w610xDCemB9DPa2ZldqyDznQjwwfga4IITwfDz/AeBrwM/jQeHHxtx6AvAQsDqE\nMBzvuQkP8P8d2BRfV3ds+yTwKHANkATHZvZWPDBeB/xcCKEvnr8WuBP4VTP7Vgjhi2Oef058zltC\nCOV4zyeAtcCfmtlXQwibD+0rBmb2cjwwvg94bWX8se1KPBD/EPDeKfS1dpymFxzquERE5Oir2eD4\nlee/DIBNixYl555Ydx8AdUXPCpda0uXaTjqt0z+I2d79o+mXZslC7+NtV7wOgK/d8rmk7e7tOwFo\nrfds79BIOhlu8WLfua7ylKZy+rxS0bPRpcz1Q/GRjfEv5EOPbUnbtvnEvf3nrPBjW7rb3q5Cnb+u\nOl+paqghfc6iNh/7afP8Z/+CTY8kbTsHdyJHztjAOJ4bMbO/B14BvBL4l1l6/G/E40crgXF8ftHM\n3odnsH+Lg4NjgN+vBMbxnrvMbAtwMvD+bGAZQthsZvcAF5tZPoRkVmnl+ddUAuN4fb+ZvR/4n/j8\nscFxKT6jnLlni5n9LZ4pfzsexB6qq+Pxt7Pjj/3faGbvwTPZkwbHIiJSW2o2OBY51pjZcuD9eBC8\nHOKe46kTZ/HxL47H741tCCE8bmbPAiebWVsIoSfT3F0tqAeew4PjalnTbfj3liXx48rzy2TKPDLu\nxIPgF1VpezqEsKXK+Tvw4LjaPVNxITAKvMnM3lSlvR5YZGadIYQ9E3UUQjiv2vmYUX5xtTYRETl2\n1WxwvOK0MwC4b1P6F9eRjmUArFy6BID9/UkyjBAzv4N9XmJY7E/jgx05z8Q2LvT7miyNaXq7Pfu6\ntRBreYfSmuOuxR7r1OX8yzyc2XQkBD9X39SWnOsZ9qXi+gc8S5zP1ByXnvWfzy2vOBeAgfnpGBpi\nTfPwiN83nCb5KMVl6PYP+rOX9qVtp2U3OpFZZWan4EuNLQDuAm4DevCgcCXwDuCgSXEzqPJG2z5O\n+3Y8YG+P46roqX45RYAxgfQBbXi9cvb5e6vUNFey17uBrip97Rjn+ZXsd9s47ZPpxL//XTfJda3A\nhMGxiIjUlpoNjkWOMX+AB2TvDCHcmG2I9bjvGHN9Gc9eVjOdlRQqQewSvE54rKVjrptpPUCHmdWF\nkFmIG1/xAlgIVJv8tnic/pZk+p3ueHIhhI5p3i8iIjVKS7mJHBmnxeNXq7RdUuXcPmCxmdVVaTt/\nnGeUSUvcx1oXj6vHNpjZacAyYMvY+tsZtA7/fvNzVdp+Dh/3Q1XalpvZyirnV2f6nY77gQVm9lPT\nvF9ERGpUzWaOe3q83GHh4nRC3jPPesJs89NPAzBSSub4EPKepMuV/dyOHelfn09c4H/t7dvmu9IV\nM/FHPn4Jy0W/r5Buakf/ft8Fz4JfP7gvLavINXhZRKGQJget5L+r7O31+xqG0gSbxflI+TqfrNfS\nmMZMLbH/fKNP0ts/msx3oqvobU0L/S/2vQvSsQ+UDvoLt8yerfG4Gvhm5aSZXYZPRBvrAbxe9Z3A\n5zLXXwlcNM4z9gAnjdP2BeA3gWvN7BshhF2xvzzwl3jg+k9TeiXT8wW81vrjZrY6BF+L0MyagU/E\na6o9Pw/8mZm9NbNaxcn4hLoi8K/THM+ngNcBnzezN4YQnss2mlkLcHYI4f5p9g/AWSe2sfYTrzuc\nLkRE5Air2eBY5BhzAx7o/ruZfQWf0HYWcDnwZeDNY67/dLz+M2b2SnwJtnPxiWT/hS+9NtbtwFvM\n7Jt4FnYUWBNCWBNCuNfM/hz4I+DhOIZ+fJ3js4C7gWmvGTyZEMIXzewX8TWKN5jZf+LrHL8Bn9j3\npRDCzVVu/TG+jvJaM7uNdJ3jduCPxpksOJXx3G5m1wAfB54ws/8GtuA1xivwbP7d+P+PiIjMITUb\nHPc/+BMAXrRoWXJuUdcpAJT7PLNaqk+zr6Ecl3fr96XcCmenCbiOOKFu3w8e9BOFNPu6pNNLFusX\nxXlB/enmHP0ln/zW0TQfgGXtC5O2lqZWAAZDf3Ju3qhnjLcP+ViGM5WZpTgpcGiHzw3K7UvLM3vj\nhDxr9iz0SG/a1rPf21p3+l/LhxvS//LtReQICSH8OK6t+1E8Y1kAfgRcgW9w8eYx1z9iZq/Cl1Z7\nPZ4lvQsPjq+genD8HjzgfCW+NFsOX+ZsTezz/Wa2Dng38Ov4hLlNwLXAX1WbLDfD3oqvTPEbwO/E\ncxuBv8I3SKlmHx7A/zn+y8J84BHgL6usiXxIQgh/FpeduxrfhOQX8VrkbXi2/rD6FxGR41PNBsci\nx5oQwr34esbVWJXr76Z6je6P8Q0sxl6/E99oY6Ix3ALcMtlY47UrJ2hbPUHblcCVVc6X8Qz6DVN8\nfvZrctAW21Wuv4PqX8fVE9xzN54hFhERAWo4OG7vOAGAvv3p0mUrOv1cYZH//ByoS+cjWqw/tiFP\npw7Vp8XDOTzTnDNvaxhK64RPafTa4bZGX0CguD/92dw/4DXGXcPe9+Kdu5O2+gGve9723FPJuUX9\ne318cSm3fbvSrHJ/fB1P3bPRx15Kt7ceGoivMefPmV9MU8LNwbPj89o9wx1a5qX31R0UR4iIiIjM\naVqtQkREREQkUnAsIiIiIhLVbFnF7qFdADy1YWNyrlD0GW7lgv9O0N+Q/m7QYD7hrbIs2mA+Lavo\n7PJShLNPPR2A1ofSpVWbNnl5xGCc+Fbal07IK8bl157s9fKIH/TtTdpKcYO7wZ79ybkTm325tY5W\n360vN5DOyMsFH2vv0z6xrtzckvYVqyjqY1lFeyH9b+2MH4dRbxtqTnfWW/HSc98nM4IAAA7+SURB\nVBARERGRlDLHIiIiIiJRzWaOt9z8bwCMPLE5OdcSJ7LHvTbIzWtI2iqZ1dKoT3TL59Pl2gYbfJm2\nNR2+JNuWbc8mbX27fWm1J2NWulhMM875Ns84DwTvc3t/miWe1+oT5PItaQaYOCmwPOrj3BHSvgZy\nPug4t4+W+W3pc4gZ4yb/76wrDiVtQ7nYV9xo7bHt6V4H57VfjIiIiIiklDkWEREREYkUHIuIiIiI\nRDVbVtHR6jvQbX/++eRcIe50F/Ayh9ah5qTN+n2t4IYBn902ms/uJOeT++7N+TU7SdcRXtHqfbTE\nyXSNDemEt531/rtHj/nzugfSdYvzDX59c2O6S9+u53YCUB7ycopd5fT17Im77Q3GnfxOWNyRtJVH\nfWOzQtnHta84mLTtG/H7Wtv8ecPt6X3dfel1IiIiIqLMsYiIiIhIomYzx0/GyW378mn8X57nk9+G\n+325NRtMl0orxAl5zXHSXmajO35S79c9EzPObZbZIa/BJ+n1NfgNu/syS7mN+LObFi/0+wq9SVv7\nqGd5T1qyMB1fr987v+Dj3N6XTuDbv78HgDi/jr27dyRtDXFc5bimW+fStM958dmNSxcB0DIvnQDY\nWJ9muUVEREREmWMRERERkUTNZo47u04AoLRyeXJuuOj1t8Sa3LpyWtRbqvPsa2/MAJea0lrgFzb5\nkmwte3wDju6QPufJ7riUW6z3LZfTxrYWr3s+Y0GXP7Y7zSrn6j37vOyUU5Nz67Z7ffTmXq9x3jUy\nkrQ1z/fxNDd67XBTY/p7zfyF7QAsWORZ4gVdXUlb4zwfe7mx0Y+ZsYdCupSdiIiIiChzLCIiIiKS\nUHAsIgcwszvMLEx+5WE/Z6WZBTO7cbafJSIiMlU1W1ZR3+YlDe1di5Nzo889A0Bdo79sK6U70Fk5\n7ohX78diQzojLwQvhzip1e8bDWk5RveAf7wg5+ULDQ3phLeBkk/kazvZSzvKmUl03b19AOzo70sH\nvbTTh9DhE+WWjKYTBufFiXRNTb50XNfitHQiV1lGLpZQ1DWmS9SVQvz9J77UQl06mTBf34iIiIiI\npGo2OBaRaft1oHnSq0RERGpQzQbHvXE+3f7G9CXWtXs2ORczvzaQTngrxeXdyn0+sa5Yn2aVMb++\nUPCsazNp5rijtQ2A/nzcdGQg3Vijt+x9PDPgS7jt6kuXchvdsxeAbTvTTUqWne6T8+pjJri+kI69\nUPCMtplnghsa0wxwod5fbD6OL+TS+8rEjHjl/lw+acvn00mHIhUhhKeP9hhERESOFtUci8wBZnal\nmX3VzDab2aCZ9ZrZPWb2tirXHlRzbGarY33w9WZ2gZl9y8z2xnMr4zVb4782M/s7M9tmZkNm9oiZ\nXW1mNvZZ44z1DDP7hJk9aGa7zGzYzJ4ys8+Z2bIq12fHdm4cW7eZDZjZnWb2snGeUzCzd5nZ/fHr\nMWBm68zs3Vb5LVREROacms0cF7q8frfu/FXJudKwL++2f+8QAAO70u2cN617GIAd23fFi9OfjZVN\nNvI5v293mnylcdizwYND+wDoKaV1wpWF23bddS8A7e3zk7aVF/0MACedcUraV+cC/yBv8ZDGJ5XM\ncS7n4wohbasMp5IJDpb+tyZZ5Eqf+Ww2Os0+S837DLABWANsBzqB1wI3mdmZIYQPTrGfC4EPAHcD\nXwAWAiOZ9nrgf4B24Jb4+S8DfwOcCfzeFJ5xBXAV8H3g3tj/TwG/BbzezM4PIWyrct/5wB8B9wH/\nCCyPz77dzM4NITxWudDM6oBvApcBjwFfBIaAlwOfBl4CvH0KYxURkRpTs8GxiBzgrBDCpuwJM6sH\nvg1cY2afHSfgHOtS4KoQwj+M074U2ByfNxyfcx3wQ+BdZvalEMKaSZ5xE/Cpyv2Z8V4ax3st8LtV\n7nsd8M4Qwo2Ze34H+CzwHuBdmWv/GA+M/w74/RBCKV6fBz4H/IaZfSWE8PVJxoqZrR2n6QWT3Ssi\nIsce/elQZA4YGxjHcyPA3+O/JL9yil2tnyAwrvhANrANIewFPhI/fecUxrptbGAcz9+GZ78vG+fW\ne7KBcfQFoAhcUDkRSyb+D/A88N5KYByfUQLeBwTg1yYbq4iI1J6azRzvGfYSiOfz6cS6nSVfNm33\nPp8M9/zTu5K2fX09AAzHyXchs3tec6xgaAhemjCQKUesL8a/KMel35rnp6UTy9u8TOKkk1YAsHJV\nWkLREJeas/p0l7qRSr+5SllFOoa6ODkvl49FFJmyCotj9aQXkM+US8RSi8o8vHw+rQmpq9MOeXOF\nmS0H3o8HwcuBpjGXnDjFrh6YpL2Il0KMdUc8vmiyB8Ta5F8DrgR+GlhAWj0EB5ZxZD049kQIYdTM\ndsQ+Ks4AOoAngGvHKYUeBFZVa6jyjPOqnY8Z5RdPpQ8RETl21GxwLCLOzE7Bg9oFwF3AbUAPvvr1\nSuAdwFR/U3p+kvbd2UxslfvapvCMTwK/j9dG3wpsw4NV8IB5xTj3dY9zvsiBwXVnPJ4OXDfBOFqn\nMFYREakxNRsch7i8WWk4zfKWBjzbmhvxSXPzmtOfl60n+aYao8OelBosFZO2ejyz1BIzu6XmdAm0\njkZPwLUu8g042roWJm2dnd5nR5v/LB7NFLEMxcl2hczSag05z/hWsru5/MGblFXNcsUMc2WZtmBp\nn7mCj7VQqNw36xufybHnD/CA8J1jyw7M7K14cDxVk72BFppZvkqAvCQeeya62cy6gKuBh4GXhRD2\nVxnv4aqM4WshhCtmoD8REakhqjkWqX2nxeNXq7RdMsPPKgDVlk5bHY/rJrn/FPz70m1VAuNlsf1w\nPYpnmV8aV60QERFJKDgWqX1b43F19qSZXYYvjzbTPm5mSZmGmXXgK0wA/PMk926Nx4vN0j+BmFkr\n8Hlm4K9dIYQivlzbUuBvzWxs/TVmttTMXni4zxIRkeNPzZZVNM3zMoclmdKERXVeQlha4iWLI5k1\niYsDPoFveNgnyadFFSR/SG6IawxbQ/pla47rBjc3eiyQz+xcl6urTIaLJR4jaa8WvK/susP5WBZh\nVEogMiUUcQzlOBEvlymvyMdyjMqsu5BLf+exKusiV2TmHEptuwFfJeLfzewrwHPAWcDlwJeBN8/g\ns7bj9csPm9k3gDrgjXggesNky7iFEJ43s1uAtwDrzew2vE751fg6xOuBc2dgnB/BJ/tdha+d/D28\ntrkLr0W+CF/u7ZEZeJaIiBxHajY4FhEXQvixmb0c+Ci+FnAB+BG+2UY3MxscjwCvAj6GB7gL8XWP\nP4Fna6fiN+M9b8Y3DdkFfAP4E6qXhhyyuIrFG4C34ZP8fh6fgLcL2AJ8ELj5MB+zcuPGjZx3XtXF\nLEREZBIbN24Enzh+RFm1jKKIyKEys60AIYSVR3ckxwYzG8ZXyfjR0R6LzGmVzWgePaqjkLluuu/D\nlUBvCOHkmR3OxJQ5FhGZHQ/D+OsgixwJlR0c9T6Uo+l4ex9qQp6IiIiISKTgWEREREQkUlmFiMwI\n1RqLiEgtUOZYRERERCRScCwiIiIiEmkpNxERERGRSJljEREREZFIwbGIiIiISKTgWEREREQkUnAs\nIiIiIhIpOBYRERERiRQci4iIiIhECo5FRERERCIFxyIiU2Bmy8zsC2b2nJkNm9lWM/trM1twiP10\nxPu2xn6ei/0um62xS+2Yifehmd1hZmGCf42z+Rrk+GZmbzSzT5vZXWbWG98z/zrNvmbk++pMKxzN\nh4uIHA/M7FTgXqAL+DrwKHAB8B7gcjO7KISwZwr9dMZ+zgC+B9wCvAB4J/A6M7swhLB5dl6FHO9m\n6n2Y8aFxzhcPa6BS664FfhroA57Fv4cdsll4P88YBcciIpO7Af8GfnUI4dOVk2b2SeC9wJ8CV02h\nn4/hgfEnQwjvy/RzNfA38TmXz+C4pbbM1PsQgBDC9TM9QJkT3osHxU8ClwDfn2Y/M/p+nknaPlpE\nZAIxu/EksBU4NYRQzrTNA7YDBnSFEPon6KcV2AmUgaUhhP2ZthywGVgRn6HssRxgpt6H8fo7gEtC\nCDZrA5Y5wcxW48HxzSGEtx3CfTP2fp4NqjkWEZnYy+Pxtuw3cIAY4N4DNAMvnaSflwJNwD3ZwDj2\nUwZuHfM8kayZeh8mzOzNZnaNmf2Bmb3GzBpmbrgiE5rx9/NMUnAsIjKxM+Px8XHan4jHM45QPzI3\nzcb75xbg48BfAf8NPG1mb5ze8EQOyTH9/VDBsYjIxNrisWec9sr59iPUj8xNM/n++TrwemAZ/teM\nF+BBcjvwJTNT3bvMtmP6+6Em5ImIiMwhIYRPjTn1GPD/zOw54NN4oPydIz4wkWOEMsciIhOrZDDa\nxmmvnO8+Qv3I3HQk3j//iC/jdm6cFCUyW47p74cKjkVEJvZYPI5X+3Z6PI5XOzfT/cjcNOvvnxDC\nEFCZLNoy3X5EpuCY/n6o4FhEZGKVNTwvjUuuJWJ27SJgALh/kn7uBwaBi8Zm5WK/l455nkjWTL0P\nx2VmZwIL8AB593T7EZmCWX8/Hw4FxyIiEwghbAJuA1YCvzem+UN4hu2m7FqcZvYCMztg16gQQh9w\nU7z++jH9vDv2f6vWOJZqZup9aGYnm1nH2P7NbBHwz/HTW0II2iVPDpuZ1cX34anZ89N5Px9J2gRE\nRGQSVbY53Qi8BF+r83HgZdltTs0sAIzdZKHK9tEPAKuAX8Q3CHlZ/KEhcpCZeB+a2ZXAZ4G78Y1n\n9gLLgdfidZ4PAq8OIaj2XaoyszcAb4ifLgEuw99Ld8Vzu0MIfxivXQlsAZ4KIawc088hvZ+PJAXH\nIiJTYGYnAR/Gt3fuxHdw+hrwoRDCvjHXVg2OY1sHcB3+w2UpsAf4NvAnIYRnZ/M1yPHvcN+HZnY2\n8D7gPOAEYD5eRrEB+DLwDyGEkdl/JXK8MrPr8e9h40kC4YmC49g+5ffzkaTgWEREREQkUs2xiIiI\niEik4FhEREREJFJwLCIiIiISKTgWEREREYkUHIuIiIiIRAqORUREREQiBcciIiIiIpGCYxERERGR\nSMGxiIiIiEik4FhEREREJFJwLCIiIiISKTgWEREREYkUHIuIiIiIRAqORUREREQiBcciIiIiIpGC\nYxERERGRSMGxiIiIiEj0v6EMT0jpXccBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7effb09df208>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
